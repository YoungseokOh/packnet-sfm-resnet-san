# ST2 Dual-Head Training Configuration - NCDB 640x384
# Purpose: Complete ST2 Dual-Head training on NCDB dataset
# Resolution: 640x384
# Depth Range: 0.5m - 15.0m (near-field)
# Based on: docs/quantization/ST2/Quick_Reference.md

model:
    name: 'SemiSupCompletionModel'
    
    # Loss configuration
    loss:
        supervised_method: 'sparse-ssi-silog'
        supervised_num_scales: 1
        supervised_loss_weight: 1.0
        # üÜï SSI-Silog + Gradient Loss weights
        ssi_weight: 0.4             # SSI loss component (balanced)
        silog_weight: 0.4           # Silog loss component (balanced)
        gradient_weight: 0.2        # üÜï Gradient loss for edge preservation
        gradient_scales: 4          # üÜï Multi-scale: 1, 1/2, 1/4, 1/8
    
    # Optimizer configuration
    optimizer:
        name: 'Adam'
        depth:
            lr: 0.0002              # ‚≠ê Dual-Head recommended learning rate (2e-4)
        pose:
            lr: 0.0001
    
    # Scheduler configuration
    scheduler:
        name: 'StepLR'
        step_size: 30
        gamma: 0.5
    
    # Depth Network configuration
    depth_net:
        name: 'ResNetSAN01'
        version: '18A'
        use_dual_head: true           # ‚≠ê Enable Dual-Head architecture
        use_film: True               # Disable FiLM for pure depth prediction test
        use_enhanced_lidar: false     # Disable Enhanced LiDAR for simplicity
    
    # Depth range configuration (NCDB: near-field)
    params:
        crop: ''
        min_depth: 0.1                # ‚≠ê NCDB near-field minimum
        max_depth: 15.0               # ‚≠ê NCDB near-field maximum
        scale_output: 'top-center'
        use_log_space: false

# Dataset configuration (NCDB)
datasets:
    augmentation:
        image_shape: [384, 640]
    train:
        batch_size: 12
        dataset: ['ncdb']
        path: ['/workspace/data/ncdb-cls-640x384']
        split: ['splits/combined_train.json']
        depth_type: ['depth_original']  # ‚≠ê 'depth'/'distance' (syntheticÌè¨Ìï®) or 'depth_original'/'distance_original' (ÏõêÎ≥∏Îßå)
        mask_file: ['binary_mask.png']
        use_mask: [false]
    validation:
        dataset: ['ncdb']
        path: ['/workspace/data/ncdb-cls-640x384']
        split: ['splits/combined_val.json']
        depth_type: ['depth_original']  # ‚≠ê 'depth'/'distance' (syntheticÌè¨Ìï®) or 'depth_original'/'distance_original' (ÏõêÎ≥∏Îßå)
        mask_file: ['binary_mask.png']
        use_mask: [false]
    test:
        dataset: ['ncdb']
        path: ['/workspace/data/ncdb-cls-640x384']
        split: ['splits/combined_test.json']
        depth_type: ['depth_original']  # ‚≠ê 'depth'/'distance' (syntheticÌè¨Ìï®) or 'depth_original'/'distance_original' (ÏõêÎ≥∏Îßå)
        mask_file: ['binary_mask.png']
        use_mask: [false]

# Architecture settings
arch:
    seed: 42
    clip_grad: 1.0
    max_epochs: 50                    # ‚≠ê Full training: 50 epochs
    eval_during_training: true
    eval_progress_interval: 0.5
    eval_subset_size: 100

# Checkpoint configuration

############################################
# UF means 'Use Film'
# Original means 'original depth maps' from NCDB
# 0.1 to 15m depth range
# resnetsan means ResNetSAN01 architecture
############################################

checkpoint:
    filepath: 'checkpoints/resnetsan01_dual_head_ncdb_original_640x384_0.1_to_15m_Gradient Loss/'
    save_top_k: -1                    # Save all checkpoints (team policy)
    period: 1                         # Save every 2 epochs (disk optimization)

# Save configuration
save:
    folder: 'outputs/resnetsan01_dual_head_fixed_ncdb_original_640x384_0.1_to_15m_Gradient Loss/'

# Tensorboard logging
tensorboard:
    dry_run: false
    log_frequency: 100
