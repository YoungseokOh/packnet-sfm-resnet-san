model:
    name: 'SemiSupCompletionModel'
    loss:
        supervised_method: 'sparse-ssi-silog'
        supervised_num_scales: 1
        supervised_loss_weight: 1.0
    optimizer:
        name: 'Adam'
        depth:
            lr: 0.0001
        pose:
            lr: 0.0001
    scheduler:
        name: 'StepLR'
        step_size: 25
        gamma: 0.5
    depth_net:
        name: 'ResNetSAN01'
        version: '18A'
        dropout: 0.1
        # ğŸ”§ ê¸°ì¡´ êµ¬ì¡°ë¡œ ì„¤ì •
        use_film: false           # ì²´í¬í¬ì¸íŠ¸ì™€ ë™ì¼í•˜ê²Œ
        film_scales: [0]         # ì²´í¬í¬ì¸íŠ¸ì™€ ë™ì¼í•˜ê²Œ
        use_enhanced_lidar: false  # âŒ Enhanced ë¹„í™œì„±í™”
    params:
        crop: ''
        min_depth: 0.0
        max_depth: 80.0
        scale_output: 'top-center'

datasets:
    train:
        batch_size: 4 # Reduced for larger image size
        dataset: ['ncdb']
        path: ['/workspace/data/ncdb-cls']
        split: ['splits/combined_train.json']
        repeat: [1]
        mask_file: ['binary_mask.png']
    validation:
        batch_size: 1 # Reduced for larger image size
        dataset: ['ncdb']
        path: ['/workspace/data/ncdb-cls']
        split: ['splits/combined_val.json']
        mask_file: ['binary_mask.png']
    test:
        batch_size: 1 # Reduced for larger image size
        dataset: ['ncdb']
        path: ['/workspace/data/ncdb-cls']
        split: ['splits/combined_test.json']
        mask_file: ['binary_mask.png']

# ğŸ†• ì¤‘ê°„ í‰ê°€ ì„¤ì •
arch:
    seed: 42
    clip_grad: 10.0
    max_epochs: 30 # Increased for longer training
    eval_during_training: true
    eval_progress_interval: 0.5
    eval_subset_size: 100

checkpoint:
    filepath: 'checkpoints/resnetsan01_newest_test_sparse-ssi-silog/'
    save_top_k: -1

save:
    folder: 'outputs/resnetsan01_newest_test_sparse-ssi-silog/'

tensorboard:
    dry_run: false
    log_frequency: 10 # Log depth every 10 steps