#!/usr/bin/env python3
"""
í†µí•© ìŠ¤í”Œë¦¿ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
- ì—¬ëŸ¬ í´ë”ì—ì„œ image_a6/*.png ë˜ëŠ” *.jpg íŒŒì¼ë“¤ì„ ìŠ¤ìº”í•˜ì—¬ ìŠ¤í”Œë¦¿ ìƒì„±
- ê°„ë‹¨í•œ JSON í¬ë§·: dataset_root + new_filenameë§Œ í¬í•¨
- 80/10/10 ê¸°ë³¸ ë¹„ìœ¨
"""

import json
import random
import argparse
from pathlib import Path
from tqdm import tqdm


def scan_dataset_folder(dataset_root):
    """ë°ì´í„°ì…‹ í´ë”ë¥¼ ìŠ¤ìº”í•˜ì—¬ ìœ íš¨í•œ ìƒ˜í”Œ ëª©ë¡ ìƒì„±"""
    dataset_root = Path(dataset_root)
    image_dir = dataset_root / 'image_a6'
    
    if not image_dir.exists():
        print(f"âš ï¸  image_a6 í´ë” ì—†ìŒ: {dataset_root}")
        return []
    
    # ì´ë¯¸ì§€ íŒŒì¼ ìŠ¤ìº” (.png, .jpg)
    image_files = list(image_dir.glob('*.png')) + list(image_dir.glob('*.jpg'))
    
    samples = []
    for img_path in image_files:
        stem = img_path.stem
        samples.append({
            "dataset_root": str(dataset_root),
            "new_filename": stem
        })
    
    return samples


def create_combined_splits(dataset_roots, output_dir,
                           train_ratio=0.80, val_ratio=0.10, test_ratio=0.10,
                           seed=42):
    """ì—¬ëŸ¬ ë°ì´í„°ì…‹ í´ë”ë¥¼ í†µí•©í•˜ì—¬ train/val/test ìŠ¤í”Œë¦¿ì„ ìƒì„±"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¹„ìœ¨ ê²€ì¦
    total_ratio = train_ratio + val_ratio + test_ratio
    if abs(total_ratio - 1.0) > 1e-6:
        raise ValueError(f"ë¹„ìœ¨ í•©ì´ 1.0ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {total_ratio}")
    
    print(f"\n{'='*60}")
    print("ğŸ“‚ ë°ì´í„°ì…‹ ìŠ¤ìº” ì¤‘...")
    print(f"{'='*60}")
    
    all_samples = []
    for root in tqdm(dataset_roots, desc="í´ë” ìŠ¤ìº”"):
        samples = scan_dataset_folder(root)
        print(f"  ï¿½ï¿½ {Path(root).name}: {len(samples):,}ê°œ ìƒ˜í”Œ")
        all_samples.extend(samples)
    
    print(f"\nì´ ìƒ˜í”Œ ìˆ˜: {len(all_samples):,}ê°œ")
    
    # ëœë¤ ì…”í”Œ
    random.seed(seed)
    random.shuffle(all_samples)
    
    # ìŠ¤í”Œë¦¿ ê³„ì‚°
    total = len(all_samples)
    train_end = int(total * train_ratio)
    val_end = train_end + int(total * val_ratio)
    
    train_data = all_samples[:train_end]
    val_data = all_samples[train_end:val_end]
    test_data = all_samples[val_end:]
    
    # ì €ì¥
    print(f"\n{'='*60}")
    print("ğŸ’¾ ìŠ¤í”Œë¦¿ íŒŒì¼ ì €ì¥ ì¤‘...")
    print(f"{'='*60}")
    
    splits = {
        'combined_train.json': train_data,
        'combined_val.json': val_data,
        'combined_test.json': test_data
    }
    
    for filename, data in splits.items():
        filepath = output_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"  âœ… {filename}: {len(data):,}ê°œ ({len(data)/total*100:.1f}%)")
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ìŠ¤í”Œë¦¿ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"  â€¢ ì¶œë ¥ í´ë”: {output_dir}")
    print(f"  â€¢ Train: {len(train_data):,}ê°œ ({train_ratio*100:.0f}%)")
    print(f"  â€¢ Val:   {len(val_data):,}ê°œ ({val_ratio*100:.0f}%)")
    print(f"  â€¢ Test:  {len(test_data):,}ê°œ ({test_ratio*100:.0f}%)")
    print(f"  â€¢ ëœë¤ ì‹œë“œ: {seed}")
    
    return train_data, val_data, test_data


def main():
    parser = argparse.ArgumentParser(description='í†µí•© train/val/test ìŠ¤í”Œë¦¿ ìƒì„±')
    parser.add_argument('--datasets', '-d', nargs='+', required=True, help='ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œë“¤')
    parser.add_argument('--output', '-o', required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--ratio', '-r', nargs=3, type=float, default=[0.80, 0.10, 0.10], help='train/val/test ë¹„ìœ¨')
    parser.add_argument('--seed', '-s', type=int, default=42, help='ëœë¤ ì‹œë“œ')
    
    args = parser.parse_args()
    
    create_combined_splits(
        dataset_roots=args.datasets,
        output_dir=args.output,
        train_ratio=args.ratio[0],
        val_ratio=args.ratio[1],
        test_ratio=args.ratio[2],
        seed=args.seed
    )


if __name__ == '__main__':
    main()
