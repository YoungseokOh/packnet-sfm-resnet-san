import torch
import torch.nn as nn

class SSITrimLoss(nn.Module):
    """
    Scale- and Shift-Invariant Trimmed L1-Loss (MiDaS `L_ssitrim`)

    Args
    ----
    trim : float, optional
        Fraction (0â€’1) of highest-error pixels to discard. 0 â†’ no trimming.
    epsilon : float, optional
        Small number to stabilise pseudo-inverse when var(pred) â‰ˆ 0.
    """
    def __init__(self, trim: float = 0.2, epsilon: float = 1e-6):
        super().__init__()
        assert 0.0 <= trim < 1.0, "trim must be in [0,1)"
        self.trim = trim
        self.eps = epsilon

    @staticmethod
    def _solve_scale_shift(pred, gt, mask, eps):
        """Closed-form Î±, Î² solving â€–Î± d + Î² â€“ zâ€–Â² (least-squares)."""
        # flatten valid pixels
        d = pred[mask]                # (N,)
        z = gt[mask]
        if d.numel() == 0:            # empty mask â†’ return neutral Î±,Î²
            return torch.tensor(1.0, device=pred.device), torch.tensor(0.0, device=pred.device)
        mean_d, mean_z = d.mean(), z.mean()
        var_d   = (d * d).mean() - mean_d ** 2
        cov_dz  = (d * z).mean() - mean_d * mean_z
        alpha   = cov_dz / (var_d + eps)
        beta    = mean_z - alpha * mean_d
        return alpha, beta

    def forward(self, pred, gt, mask=None):
        """
        pred, gt : (B, 1, H, W) -or- (B, H, W)
        mask     : bool/int same shape, True/1 = valid GT.  None â†’ all valid.
        """
        if pred.dim() == 4:     # squeeze channel dim if present
            pred, gt = pred.squeeze(1), gt.squeeze(1)
            if mask is not None and mask.dim() == 4:
                mask = mask.squeeze(1)

        B = pred.shape[0]
        total = 0.0
        for b in range(B):
            mb = torch.ones_like(gt[b], dtype=torch.bool) if mask is None else mask[b] > 0
            Î±, Î² = self._solve_scale_shift(pred[b], gt[b], mb, self.eps)
            # aligned residuals
            res  = torch.abs(Î± * pred[b] + Î² - gt[b])
            res  = res[mb]                     # apply mask

            if self.trim > 0 and res.numel() > 0:
                k = int((1.0 - self.trim) * res.numel())
                if k > 0:  # ğŸ†• kê°€ 0ë³´ë‹¤ í´ ë•Œë§Œ trimming ìˆ˜í–‰
                    # ğŸ”§ ì •ë ¬ì„ ì‚¬ìš©í•´ì„œ ìƒìœ„ trim% ì œê±°
                    res_sorted, _ = torch.sort(res)
                    res = res_sorted[:k]  # ì‘ì€ kê°œë§Œ ì„ íƒ (ìƒìœ„ trim% ì œê±°)
                # kê°€ 0ì´ë©´ ëª¨ë“  ê°’ ì œê±°í•˜ë¯€ë¡œ ë¹ˆ í…ì„œë¡œ ë§Œë“¦
                elif k == 0:
                    res = torch.tensor([], device=res.device, dtype=res.dtype)
            
            # ğŸ†• ë¹ˆ í…ì„œ ì²˜ë¦¬
            if res.numel() > 0:
                total += res.mean()
            else:
                # ìœ íš¨í•œ í”½ì…€ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬
                total += torch.tensor(0.0, device=pred.device, dtype=pred.dtype)
        
        return total / B