# Checkpoint Monitoring Root Cause Fix
**ë‹´ë‹¹ì**: World-Class Developer  
**ì‘ì„±ì¼**: 2024-12-19  
**ìƒíƒœ**: ğŸ“‹ Planning (ë¯¸ì ìš©)  
**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ Medium (í•˜ì§€ë§Œ ê¶Œì¥)  
**ì˜í–¥ë„**: ğŸ”§ Code Quality + ê¸°ëŠ¥ì„±

---

## ğŸ“‹ Executive Summary

**ë¬¸ì œ**: `save_top_k` íŒŒë¼ë¯¸í„°ê°€ checkpoint ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ ë¶€ì¬ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ  
**ê·¼ë³¸ ì›ì¸**: `validation_epoch_end()`ì—ì„œ `'loss'` ë©”íŠ¸ë¦­ì´ ë°˜í™˜ë˜ì§€ ì•ŠìŒ  
**í˜„ì¬ ìƒíƒœ**: ìš°íšŒ í•´ê²°ì±…(save_top_k: -1) ì ìš©ë¨  
**ìµœì  í•´ê²°ì±…**: 2ë‹¨ê³„ ê·¼ë³¸ ì›ì¸ í•´ê²°

---

## ğŸ” ë¬¸ì œ ë¶„ì„

### 1. ë¬¸ì œ ì§€ì 

#### í˜„ìƒ
```yaml
checkpoint:
    save_top_k: 3              # âŒ ì‘ë™í•˜ì§€ ì•ŠìŒ
    monitor: 'loss'            # âŒ ë©”íŠ¸ë¦­ ì—†ìŒ
```

í•™ìŠµ ì¤‘ checkpoint ì €ì¥ ì‹œ:
```
AssertionError: Checkpoint metric is not available
```

#### ê·¼ë³¸ ì›ì¸ ì¶”ì 

**Step 1**: model_checkpoint.py (Line 140-141)
```python
if self.save_top_k != -1:
    current = metrics.get(self.monitor)        # 'loss' ì°¾ìŒ
    assert current, 'Checkpoint metric is not available'  # âŒ ì‹¤íŒ¨
```

**Step 2**: horovod_trainer.py (Line 123)
```python
validation_output = self.validate(val_dataloaders, module)
self.check_and_save(module, validation_output)  # metrics ì „ë‹¬
```

**Step 3**: model_wrapper.py (Line 449-515)
```python
def validation_epoch_end(self, output_data_batch):
    metrics_dict = create_dict(...)  # 'loss' ì—†ìŒ!
    return metrics_dict              # âŒ 'loss' í‚¤ ë¶€ì¬
```

**Step 4**: reduce.py (Line 117-150)
```python
def create_dict(metrics_data, metrics_keys, metrics_modes, ...):
    # metrics_keys = ('abs_rel', 'sqr_rel', 'rmse', ...)
    # 'loss'ëŠ” í¬í•¨ë˜ì§€ ì•ŠìŒ!
    for i, key in enumerate(metrics_keys):  # â† 'loss' ì—†ìŒ
        metrics_dict[f'{prefix}-{key}{mode}'] = ...
    return metrics_dict  # âŒ 'loss' í‚¤ ì—†ëŠ” ìƒíƒœ
```

---

## ğŸ’¡ í•´ê²° ë°©ì•ˆ (2ê°€ì§€)

### ë°©ì•ˆ A: YAML ì„¤ì • ë³€ê²½ (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

#### ì„¤ëª…
ì´ë¯¸ `validation_epoch_end()`ì—ì„œ ë°˜í™˜ë˜ëŠ” ë©”íŠ¸ë¦­(`'depth-abs_rel0'`)ì„ ì‚¬ìš©

#### íŒŒì¼: `configs/train_resnet_san_ncdb_dual_head_640x384.yaml`

**ìˆ˜ì • ì „**:
```yaml
checkpoint:
    filepath: 'checkpoints/resnetsan01_dual_head_ncdb_640x384/'
    save_top_k: -1                    # ëª¨ë“  checkpoint ì €ì¥ (ìš°íšŒ)
    period: 2                         # 2 epochë§ˆë‹¤ ì €ì¥
```

**ìˆ˜ì • í›„**:
```yaml
checkpoint:
    filepath: 'checkpoints/resnetsan01_dual_head_ncdb_640x384/'
    save_top_k: 3                     # â­ ìƒìœ„ 3ê°œ ìœ ì§€
    monitor: 'depth-abs_rel0'         # â­ ê¸°ì¡´ ë©”íŠ¸ë¦­ ì‚¬ìš©
    mode: 'min'                       # â­ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
    period: 1                         # â­ ë§¤ epoch í™•ì¸
```

#### ì‘ë™ ì›ë¦¬

```python
# create_dict() ì‹¤í–‰ ê²°ê³¼
metrics_dict = {
    'depth-abs_rel0': 0.120,      # âœ… ì¡´ì¬!
    'depth-sqr_rel0': 0.045,
    'depth-rmse0': 0.50,
    ...
}

# ModelCheckpoint.check_and_save()
current = metrics_dict.get('depth-abs_rel0')  # âœ… 0.120 íšë“
assert current  # âœ… ì„±ê³µ!
# â†’ save_top_k ëª¨ë‹ˆí„°ë§ ì •ìƒ ì‘ë™
```

#### ì¥ì 
- âœ… YAMLë§Œ ìˆ˜ì • (1ë¶„)
- âœ… ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”
- âœ… ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
- âœ… ì•ˆì „ (ê²€ì¦ëœ ë©”íŠ¸ë¦­)

#### ë‹¨ì 
- âš ï¸ ë©”íŠ¸ë¦­ í‚¤ ì´ë¦„ ëª…ì‹œì  í•„ìš” (`depth-abs_rel0`)
- âš ï¸ `monitor` ê¸°ë³¸ê°’(`'loss'`)ê³¼ ë¶ˆì¼ì¹˜

#### ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] 'depth-abs_rel0'ê°€ create_dict()ì—ì„œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
  ```python
  # model_wrapper.py Line 60
  self.metrics_keys = ('abs_rel', 'sqr_rel', 'rmse', ...)  # âœ…
  # reduce.py Line 137
  metrics_dict['depth-abs_rel0'] = ...  # âœ… ìƒì„±ë¨
  ```
- [ ] ModelCheckpointì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸
  ```python
  # model_checkpoint.py Line 140
  current = metrics.get('depth-abs_rel0')  # âœ… ì ‘ê·¼ ê°€ëŠ¥
  ```
- [ ] YAML íŒŒì¼ ìœ íš¨ì„± í™•ì¸
  ```bash
  python -c "from packnet_sfm.utils.config import parse_train_file; \
  config, _ = parse_train_file('configs/train_resnet_san_ncdb_dual_head_640x384.yaml'); \
  print(config.checkpoint.monitor)"
  ```

---

### ë°©ì•ˆ B: ì½”ë“œ ìˆ˜ì • (ê·¼ë³¸ í•´ê²°)

#### ì„¤ëª…
`validation_epoch_end()`ì—ì„œ validation lossë¥¼ metrics_dictì— ì¶”ê°€

#### íŒŒì¼ 1: `packnet_sfm/models/model_wrapper.py`

**ìœ„ì¹˜**: `validation_epoch_end()` í•¨ìˆ˜ ë‚´, ë§ˆì§€ë§‰ return ì „

**í˜„ì¬ ì½”ë“œ** (ë¼ì¸ 490-512):
```python
        # Log to wandb
        if self.loggers:
            # Filter metrics to log only essential validation metrics
            log_metrics = {
                'global_step': self.current_epoch + 1,
            }
            for key, val in metrics_dict.items():
                if key.startswith('depth'):
                    log_metrics[f'val/{key}'] = val
            
            # Add validation loss if available
            if val_loss is not None:
                log_metrics['val/loss'] = val_loss

            for logger in self.loggers:
                logger.log_metrics(log_metrics, step=self.current_epoch + 1)

        return {
            **metrics_dict
        }
```

**ìˆ˜ì • í›„** (ì´ ì½”ë“œ ì¶”ê°€):
```python
        # Log to wandb
        if self.loggers:
            # Filter metrics to log only essential validation metrics
            log_metrics = {
                'global_step': self.current_epoch + 1,
            }
            for key, val in metrics_dict.items():
                if key.startswith('depth'):
                    log_metrics[f'val/{key}'] = val
            
            # Add validation loss if available
            if val_loss is not None:
                log_metrics['val/loss'] = val_loss

            for logger in self.loggers:
                logger.log_metrics(log_metrics, step=self.current_epoch + 1)

        # âœ… ğŸ†• Add loss to metrics_dict for checkpoint monitoring
        # This allows save_top_k to work properly when monitor='loss' (default config)
        if output_data_batch and len(output_data_batch) > 0:
            all_losses = []
            for batch_outputs in output_data_batch:
                for output in batch_outputs:
                    if 'loss' in output:
                        loss_val = output['loss']
                        # Convert tensor to float if necessary
                        if isinstance(loss_val, torch.Tensor):
                            loss_val = loss_val.item()
                        all_losses.append(loss_val)
            
            # Average losses from all batches
            if all_losses:
                metrics_dict['loss'] = sum(all_losses) / len(all_losses)

        return {
            **metrics_dict
        }
```

#### ì‘ë™ ì›ë¦¬

```python
# ìˆ˜ì • í›„ ê²°ê³¼
metrics_dict = {
    'depth-abs_rel0': 0.120,
    'depth-sqr_rel0': 0.045,
    'depth-rmse0': 0.50,
    'loss': 0.2654,            # âœ… ğŸ†• ì¶”ê°€ë¨!
    ...
}

# ModelCheckpoint.check_and_save()
current = metrics_dict.get('loss')  # âœ… 0.2654 íšë“
assert current  # âœ… ì„±ê³µ!
# â†’ save_top_k + monitor='loss' ì •ìƒ ì‘ë™
```

#### ì¥ì 
- âœ… default_config ê¸°ë³¸ê°’ ì‚¬ìš© ê°€ëŠ¥ (`monitor: 'loss'`)
- âœ… ì½”ë“œ ì¼ê´€ì„± (val_loss ì´ë¯¸ ê³„ì‚°ë˜ê³  ìˆìŒ)
- âœ… ë‹¤ë¥¸ YAML íŒŒì¼ì—ë„ ìë™ ì ìš©
- âœ… ë²”ìš©ì„± ë†’ìŒ

#### ë‹¨ì 
- âš ï¸ ì½”ë“œ ìˆ˜ì • í•„ìš” (~15ì¤„)
- âš ï¸ í…ŒìŠ¤íŠ¸ í•„ìš”
- âš ï¸ ë‹¤ë¥¸ ëª¨ë¸ í˜¸í™˜ì„± í™•ì¸ í•„ìš”

#### ì½”ë“œ ê²€ì¦ ì‚¬í•­
- [ ] imports í™•ì¸ (torch ì´ë¯¸ ì„í¬íŠ¸ë¨)
  ```python
  # model_wrapper.py ìƒë‹¨
  import torch  # âœ… ì´ë¯¸ ìˆìŒ
  ```
- [ ] output_data_batch êµ¬ì¡° í™•ì¸
  ```python
  # ë¼ì¸ 469-475 ë¶„ì„
  for n, dataloader in enumerate(dataloaders):
      outputs = []
      for i, batch in progress_bar:
          output = module.validation_step(batch, i, n)
          outputs.append(output)  # â† ê° outputì— 'loss' ìˆìŒ
  ```
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±
  ```python
  # í™•ì¸ ë°©ë²•
  def test_validation_epoch_end_loss():
      # validation_epoch_end() í˜¸ì¶œ í›„
      metrics = model.validation_epoch_end(output_data_batch)
      assert 'loss' in metrics, "Loss key missing!"
      assert isinstance(metrics['loss'], float), "Loss should be float"
  ```

---

## ğŸ“Š ë°©ì•ˆ ë¹„êµí‘œ

| ê¸°ì¤€ | ë°©ì•ˆ A (YAML) | ë°©ì•ˆ B (ì½”ë“œ) | ìš°íšŒì±… (í˜„ì¬) |
|------|--------|--------|---------|
| **ë³µì¡ë„** | â­ ë§¤ìš° ê°„ë‹¨ | â­â­â­ ì¤‘ê°„ | - |
| **ì½”ë“œ ìˆ˜ì •** | ë¶ˆí•„ìš” | ~15ì¤„ í•„ìš” | - |
| **ì¦‰ì‹œ ì ìš©** | âœ… 1ë¶„ | âš ï¸ í…ŒìŠ¤íŠ¸ í•„ìš” | âœ… ì ìš©ë¨ |
| **ìš´ì˜ í¸ì˜ì„±** | â­ ê°„ë‹¨ | â­â­ ì¼ë°˜ | - |
| **ì½”ë“œ í’ˆì§ˆ** | - | â­â­â­ ìµœê³  | - |
| **ë²”ìš©ì„±** | í•´ë‹¹ YAMLë§Œ | ì „ì²´ ëª¨ë¸ | - |
| **ì•ˆì •ì„±** | â­ ë†’ìŒ | â­â­ ê²€ì¦ í•„ìš” | âœ… |
| **default_config í˜¸í™˜ì„±** | âš ï¸ ë‚®ìŒ | âœ… ë†’ìŒ | - |

---

## ğŸ¯ ê¶Œì¥ ì ìš© ê³„íš

### Phase 1: ì¦‰ì‹œ (ë‹¹ì¼)
**ì ìš©**: ë°©ì•ˆ A (YAML ìˆ˜ì •)
- ì‹œê°„: ~1ë¶„
- ê²€ì¦: ~2ë¶„
- ë¦¬ìŠ¤í¬: ìµœì†Œ

```yaml
checkpoint:
    save_top_k: 3
    monitor: 'depth-abs_rel0'
    mode: 'min'
    period: 1
```

### Phase 2: ë‹¨ê¸° (1ì£¼ì¼ ì´ë‚´)
**ì ìš©**: ë°©ì•ˆ B (ì½”ë“œ ìˆ˜ì •)
- ì¤€ë¹„: ì½”ë“œ ë¦¬ë·°
- í…ŒìŠ¤íŠ¸: 2-3ì‹œê°„
- PR ê²€í† : 1ì‹œê°„

**ë‹¨ê³„ë³„ ì‹¤í–‰**:
1. ì½”ë“œ ìˆ˜ì • (model_wrapper.py)
2. Unit test ì‘ì„±
3. Integration test ì‹¤í–‰
4. ë‹¤ë¥¸ ëª¨ë¸ í˜¸í™˜ì„± í™•ì¸
5. PR ì œì¶œ ë° ë¦¬ë·°

### Phase 3: ìµœì¢…
**ê²°ê³¼**:
- YAMLì—ì„œ `monitor: 'loss'` ì‚¬ìš© ê°€ëŠ¥ (default_config ê¸°ë³¸ê°’)
- ëª¨ë“  depth estimation ëª¨ë¸ì— ìë™ ì ìš©
- ë” ìš°ì•„í•œ checkpoint ê´€ë¦¬

---

## ğŸ“ ì‹¤í–‰ ì‹œ ì£¼ì˜ì‚¬í•­

### ë°©ì•ˆ B ì½”ë“œ ìˆ˜ì • ì‹œ í™•ì¸ì‚¬í•­

1. **Loss ê³„ì‚° ë°©ì‹ ê²€ì¦**
   ```python
   # val_loss ì´ë¯¸ ê³„ì‚°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ë¼ì¸ 446)
   if 'loss' in output:
       losses.append(output['loss'])
   if losses:
       val_loss = torch.tensor(losses).mean().item() if isinstance(...) else sum(losses) / len(losses)
   ```
   â†’ val_lossê°€ ì´ë¯¸ ê³„ì‚°ë¨, metrics_dictì—ë§Œ ì¶”ê°€í•˜ë©´ ë¨

2. **Tensor ë³€í™˜ ì•ˆì •ì„±**
   ```python
   # torch.Tensorì´ê±°ë‚˜ floatì¼ ìˆ˜ ìˆìŒ
   if isinstance(loss_val, torch.Tensor):
       loss_val = loss_val.item()
   ```

3. **None ê°’ ì²˜ë¦¬**
   ```python
   # ëª¨ë“  outputì— 'loss'ê°€ ìˆëŠ”ì§€ í™•ì‹¤í•˜ì§€ ì•ŠìŒ
   if all_losses:
       metrics_dict['loss'] = sum(all_losses) / len(all_losses)
   ```

4. **ë‹¤ë¥¸ ëª¨ë¸ ì˜í–¥ í™•ì¸**
   ```
   - SemiSupCompletionModel âœ“ (í˜„ì¬ í…ŒìŠ¤íŠ¸ë¨)
   - PackNetSANModel ? (í™•ì¸ í•„ìš”)
   - ë‹¤ë¥¸ Depth models ? (í™•ì¸ í•„ìš”)
   ```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê³„íš

### ë°©ì•ˆ B ì ìš© í›„ í…ŒìŠ¤íŠ¸

```python
# Test 1: Metrics ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°
def test_validation_epoch_end_structure():
    model = SemiSupCompletionModel(...)
    output = model.validation_epoch_end(output_data_batch)
    
    assert 'loss' in output, "Loss should be in metrics"
    assert 'depth-abs_rel0' in output, "abs_rel should be in metrics"
    assert isinstance(output['loss'], float), "Loss should be float"
    assert 0 < output['loss'] < 100, "Loss value reasonable"

# Test 2: Checkpoint ì €ì¥ ë™ì‘
def test_checkpoint_with_loss_monitoring():
    config = parse_train_file('configs/train_resnet_san_ncdb_dual_head_640x384.yaml')
    
    # save_top_k=3, monitor='loss'ë¡œ ì„¤ì •
    checkpoint = ModelCheckpoint(
        filepath=config.checkpoint.filepath,
        save_top_k=3,
        monitor='loss',
        mode='min'
    )
    
    # validation_outputì— 'loss' ìˆëŠ”ì§€ í™•ì¸
    validation_output = model.validation_epoch_end(batch_outputs)
    checkpoint.check_and_save(model, validation_output)
    
    # AssertionError ë°œìƒí•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
    # âœ“ checkpoint ì •ìƒ ì €ì¥

# Test 3: ìš°íšŒì±…(save_top_k=-1) ëŒ€ë¹„ ì„±ëŠ¥
def test_disk_usage_comparison():
    # Before: save_top_k=-1, period=2 â†’ 15ê°œ checkpoint (30 epoch)
    # After: save_top_k=3 â†’ 3ê°œ checkpoint ìµœëŒ€ ìœ ì§€
    
    disk_saved = 12 / 15 * 100  # 80% ë””ìŠ¤í¬ ì ˆì•½
    assert disk_saved > 50, "Should save significant disk space"
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê´€ë ¨ ì½”ë“œ ìœ„ì¹˜

| íŒŒì¼ | ë¼ì¸ | ë‚´ìš© |
|------|------|------|
| model_wrapper.py | 449-515 | validation_epoch_end() í•¨ìˆ˜ |
| reduce.py | 117-150 | create_dict() í•¨ìˆ˜ |
| model_checkpoint.py | 132-150 | check_and_save() ë¡œì§ |
| horovod_trainer.py | 123 | checkpoint í˜¸ì¶œ ì§€ì  |
| default_config.py | 245-251 | checkpoint ê¸°ë³¸ ì„¤ì • |

### ê´€ë ¨ ì´ìŠˆ

**ì´ìŠˆ**: save_top_kê°€ ì‘ë™í•˜ì§€ ì•ŠìŒ  
**ê·¼ë³¸ ì›ì¸**: validation_epoch_end()ì—ì„œ monitor ë©”íŠ¸ë¦­ ë¶€ì¬  
**ì˜í–¥ ë²”ìœ„**: save_top_k > 0 ì‚¬ìš©í•˜ëŠ” ëª¨ë“  config  
**ì‹¬ê°ë„**: ğŸ”´ High (checkpoint ê´€ë¦¬ ë¹„íš¨ìœ¨)

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°©ì•ˆ A (YAML) ì ìš© ì „
- [ ] 'depth-abs_rel0' ë©”íŠ¸ë¦­ ë°˜í™˜ í™•ì¸
- [ ] ModelCheckpointì—ì„œ ì ‘ê·¼ ê°€ëŠ¥ í™•ì¸
- [ ] YAML íŒŒì¼ ìœ íš¨ì„± ê²€ì¦

### ë°©ì•ˆ B (ì½”ë“œ) ì ìš© ì „
- [ ] loss ê°’ ë²”ìœ„ í™•ì¸ (reasonable)
- [ ] Tensor ë³€í™˜ ì•ˆì •ì„± í™•ì¸
- [ ] ë‹¤ë¥¸ ëª¨ë¸ í˜¸í™˜ì„± í™•ì¸
- [ ] ì½”ë“œ ë¦¬ë·° ì™„ë£Œ
- [ ] Unit test ì‘ì„± ì™„ë£Œ

### ë°©ì•ˆ B ì ìš© í›„
- [ ] Integration test í†µê³¼
- [ ] ë‹¤ë¥¸ ëª¨ë¸ì—ì„œ í…ŒìŠ¤íŠ¸
- [ ] Checkpoint ìƒì„± í™•ì¸
- [ ] Disk ì‚¬ìš©ëŸ‰ ë¹„êµ
- [ ] PR ë¦¬ë·° ì™„ë£Œ

---

## ğŸ“ ì—°ë½ì²˜ ë° ì°¸ê³ 

**ì‘ì„±ì**: World-Class Developer  
**ê²€ìˆ˜ì**: (í•„ìš”ì‹œ)  
**ìµœì¢… ìŠ¹ì¸**: (í•„ìš”ì‹œ)

**ê´€ë ¨ ë¬¸ì„œ**:
- [DEVELOPER_CHECKPOINT_ANALYSIS.md](../quantization/ST2/DEVELOPER_CHECKPOINT_ANALYSIS.md) - ì´ˆê¸° ë¶„ì„
- [model_checkpoint.py](../../packnet_sfm/models/model_checkpoint.py) - êµ¬í˜„ ì½”ë“œ
- [model_wrapper.py](../../packnet_sfm/models/model_wrapper.py) - ìˆ˜ì • ëŒ€ìƒ

---

**Status**: ğŸ“‹ Documentation Complete - Ready for Implementation  
**Next Step**: Phase 1 (YAML ìˆ˜ì •) ì ìš© ì‹œì‘  
**Last Updated**: 2024-12-19
