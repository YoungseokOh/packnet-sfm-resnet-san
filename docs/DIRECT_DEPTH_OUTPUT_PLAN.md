# Direct Depth Output Implementation Plan

## ğŸ¯ ëª©í‘œ
- Sigmoid ì œê±°í•˜ê³  Linear Depthë¥¼ ì§ì ‘ ì¶œë ¥
- INT8 ì–‘ìí™” ì¹œí™”ì  ì„¤ê³„ (Â±28mm ê· ì¼ ì˜¤ë¥˜)

## ğŸ“‹ ìˆ˜ì • ì‚¬í•­

### 1. ResNetSAN01.py ìˆ˜ì •

#### **Option A: depth_transform íŒŒë¼ë¯¸í„° ì¶”ê°€ (ì¶”ì²œ)** â­
```python
class ResNetSAN01(nn.Module):
    def __init__(self, min_depth=0.5, max_depth=15.0, 
                 depth_transform='bounded_inverse',  # 'linear', 'log', 'bounded_inverse'
                 **kwargs):
        self.min_depth = min_depth
        self.max_depth = max_depth
        self.depth_transform = depth_transform
        
        # DecoderëŠ” ê·¸ëŒ€ë¡œ (sigmoid ì¶œë ¥)
        self.decoder = DepthDecoder(num_ch_enc=self.encoder.num_ch_enc)
    
    def run_network(self, rgb, input_depth=None):
        # Decoder sigmoid ì¶œë ¥
        outputs = self.decoder(skip_features)  # [0, 1]
        sigmoid = outputs[("disp", 0)]
        
        # Transform sigmoid to depth
        if self.depth_transform == 'linear':
            depth = self.min_depth + (self.max_depth - self.min_depth) * sigmoid
        elif self.depth_transform == 'log':
            log_range = torch.log(torch.tensor(self.max_depth / self.min_depth))
            depth = self.min_depth * torch.exp(log_range * sigmoid)
        elif self.depth_transform == 'bounded_inverse':
            inv_min = 1.0 / self.max_depth
            inv_max = 1.0 / self.min_depth
            inv_depth = inv_min + (inv_max - inv_min) * sigmoid
            depth = 1.0 / inv_depth
        
        return depth
```

#### **ì¥ì **:
- âœ… ê¸°ì¡´ checkpoint í˜¸í™˜ (sigmoid ê°€ì¤‘ì¹˜ ì¬ì‚¬ìš©)
- âœ… YAMLì—ì„œ depth_transformë§Œ ë³€ê²½
- âœ… Bounded Inverse / Linear / Log ëª¨ë‘ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- âœ… Decoder êµ¬ì¡° ìˆ˜ì • ë¶ˆí•„ìš”

#### **ë‹¨ì **:
- Sigmoid â†’ Linear ë³€í™˜ ì˜¤ë²„í—¤ë“œ (negligible)

---

#### **Option B: Direct Linear Output Head** (ë” ê¹”ë”í•˜ì§€ë§Œ ì¬í•™ìŠµ í•„ìš”)
```python
class ResNetSAN01(nn.Module):
    def __init__(self, min_depth=0.5, max_depth=15.0, 
                 use_sigmoid=False,  # NEW: False for direct depth
                 **kwargs):
        self.min_depth = min_depth
        self.max_depth = max_depth
        self.use_sigmoid = use_sigmoid
        
        if use_sigmoid:
            # Original: Sigmoid output
            self.decoder = DepthDecoder(num_ch_enc=self.encoder.num_ch_enc)
        else:
            # NEW: Direct Depth output
            self.depth_head = nn.Sequential(
                nn.Conv2d(self.decoder.num_ch_dec[0], 1, kernel_size=1),
                nn.ReLU(),  # Ensure non-negative
            )
    
    def run_network(self, rgb, input_depth=None):
        features = self.decoder_network(skip_features)  # No sigmoid
        
        if self.use_sigmoid:
            # Original path
            depth_logits = self.sigmoid_head(features)
            sigmoid = torch.sigmoid(depth_logits)
            # Transform to depth...
        else:
            # NEW: Direct depth
            depth_logits = self.depth_head(features)
            depth = torch.clamp(depth_logits, min=self.min_depth, max=self.max_depth)
        
        return depth
```

#### **ì¥ì **:
- âœ… ê°€ì¥ ê¹”ë”í•œ êµ¬ì¡°
- âœ… Sigmoid ë³€í™˜ ì—†ìŒ (faster)
- âœ… INT8 ì–‘ìí™” ìµœì í™”

#### **ë‹¨ì **:
- âŒ ê¸°ì¡´ checkpoint ì‚¬ìš© ë¶ˆê°€ (ì¬í•™ìŠµ í•„ìˆ˜)
- âŒ DepthDecoder êµ¬ì¡° ìˆ˜ì • í•„ìš”

---

### 2. Loss ê³„ì‚° ìˆ˜ì •

#### í˜„ì¬ êµ¬ì¡°:
```python
# SemiSupCompletionModel.py
def forward(self, batch):
    inv_depths = self.depth_net(rgb)  # Sigmoid outputs [0, 1]
    
    # Convert to depth for loss
    pred_depth = inv2depth(inv_depths)
    
    # Loss (SSI + Silog)
    loss = self.loss_fn(inv_depths, gt_inv_depth)  # SSI in inv_depth
```

#### ìˆ˜ì • (Option A ê¸°ì¤€):
```python
# SemiSupCompletionModel.py
def forward(self, batch):
    depths = self.depth_net(rgb)  # Direct depth [0.5, 15.0]m
    
    # Loss (SSI + Silog)
    # SSIëŠ” ë‚´ë¶€ì—ì„œ inv_depth ë³€í™˜
    loss = self.loss_fn(depths, gt_depth)
```

#### ssi_silog_loss.py ìˆ˜ì •:
```python
class SSISilogLoss:
    def forward(self, pred_depth, gt_depth, mask=None):
        # âœ… SSI: Convert to inv_depth internally
        pred_inv = 1.0 / pred_depth
        gt_inv = 1.0 / gt_depth
        ssi_loss = self.compute_ssi_loss_inv(pred_inv, gt_inv, mask)
        
        # âœ… Silog: Use depth directly
        silog_loss = self.compute_silog_loss(pred_depth, gt_depth, mask)
        
        return self.ssi_weight * ssi_loss + self.silog_weight * silog_loss
```

---

### 3. YAML ì„¤ì •

#### train_resnet_san_ncdb_640x384_direct_linear.yaml:
```yaml
model:
  arch: ResNetSAN01
  version: 18A
  min_depth: 0.5
  max_depth: 15.0
  depth_transform: 'linear'  # NEW! 'linear', 'log', 'bounded_inverse'
  use_film: false
  
  loss:
    supervised_method: 'sparse-ssi-silog'
    ssi_weight: 0.7
    silog_weight: 0.3
    min_depth: 0.5
    max_depth: 15.0
```

---

### 4. INT8 Quantization (ONNX)

#### FP32 ONNX Export:
```python
# scripts/export_onnx.py
model = ResNetSAN01(depth_transform='linear', min_depth=0.5, max_depth=15.0)
model.eval()

dummy_input = torch.randn(1, 3, 384, 640)
torch.onnx.export(
    model,
    dummy_input,
    "resnetsan_linear_depth.onnx",
    input_names=['rgb'],
    output_names=['depth'],  # [0.5, 15.0]m range
    opset_version=11
)
```

#### NPU INT8 Quantization:
```python
# Quantization parameters
scale = (15.0 - 0.5) / 255  # 0.056863
zero_point = 0

# FP32 â†’ INT8
depth_fp32 = model(rgb)  # [0.5, 15.0]m
int8_value = ((depth_fp32 - 0.5) / scale).to(torch.uint8)  # [0, 255]

# INT8 â†’ FP32 (NPU dequantization)
depth_reconstructed = 0.5 + scale * int8_value.to(torch.float32)

# Error: Â±28mm (uniform)
```

---

## ğŸ”§ Implementation Strategy

### **Phase 1: ê¸°ì¡´ Checkpoint í™œìš© (ì¦‰ì‹œ í…ŒìŠ¤íŠ¸)**

1. **ResNetSAN01.py ìˆ˜ì • (Option A)**:
   - `depth_transform` íŒŒë¼ë¯¸í„° ì¶”ê°€
   - `run_network()`ì—ì„œ Linear ë³€í™˜ ì¶”ê°€

2. **YAML ìƒì„±**:
   - `train_resnet_san_ncdb_640x384_linear.yaml`
   - `depth_transform: 'linear'` ì„¤ì •

3. **í…ŒìŠ¤íŠ¸**:
   ```bash
   python scripts/eval.py --checkpoint checkpoints/resnetsan_linear_05_15.ckpt \
                          --config configs/eval_resnet_san_kitti.yaml \
                          --depth_transform linear
   ```

4. **ì˜ˆìƒ ê²°ê³¼**:
   - abs_rel: 0.030 (PyTorch FP32)
   - ì„±ëŠ¥ ë³€í™” í™•ì¸ (Linear vs Bounded Inverse)

---

### **Phase 2: ì¬í•™ìŠµ (Linear Depth ìµœì í™”)**

1. **Full Training**:
   ```bash
   python scripts/train.py configs/train_resnet_san_ncdb_640x384_linear.yaml
   ```

2. **ëª©í‘œ**:
   - Training = Inference (ì™„ë²½í•œ ì¼ì¹˜)
   - INT8 ì–‘ìí™” ì¹œí™”ì  í•™ìŠµ

---

### **Phase 3: INT8 Quantization**

1. **ONNX Export**:
   ```bash
   python scripts/export_onnx.py --checkpoint checkpoints/linear_depth.ckpt \
                                  --output onnx/resnetsan_linear_int8.onnx
   ```

2. **NPU INT8 Quantization**:
   - scale=0.056863, zero_point=0
   - ì˜ˆìƒ: abs_rel < 0.035 (vs 0.114 Bounded Inverse)

---

## ğŸ“Š Expected Results

| Method | Training | Inference | INT8 Error @ 15m | abs_rel (Expected) |
|--------|----------|-----------|------------------|-------------------|
| **Bounded Inverse** (í˜„ì¬) | Inv-Depth | Sigmoidâ†’Inv | 853mm | 0.114 (NPU INT8) |
| **Linear (Phase 1)** | Inv-Depth | Sigmoidâ†’Linear | 28mm | 0.040 (ì˜ˆìƒ) |
| **Linear (Phase 2)** | Linear | Linear | 28mm | 0.032 (ì˜ˆìƒ) |

---

## âœ… Action Items

1. âœ… INT8 ë¶„ì„ ì™„ë£Œ (Â±28mm ê· ì¼ ì˜¤ë¥˜)
2. ğŸ”„ ResNetSAN01.py ìˆ˜ì • (Option A)
3. ğŸ”„ ssi_silog_loss.py ìˆ˜ì •
4. ğŸ”„ YAML ì„¤ì • ìƒì„±
5. ğŸ”„ Phase 1 í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ checkpoint)
6. â¸ï¸ Phase 2 ì¬í•™ìŠµ (ì„ íƒ)
7. â¸ï¸ Phase 3 INT8 Quantization

