# ğŸ› CRITICAL BUG: Silog Loss Formula Error

## ë¬¸ì œ ë°œê²¬

**ì¦ìƒ**: Lossê°€ 1.42~1.45ì—ì„œ ë©ˆì¶¤, í•™ìŠµì´ ì „í˜€ ì§„í–‰ë˜ì§€ ì•ŠìŒ

**ì›ì¸**: Silog Loss ê³µì‹ì´ ì˜ëª» êµ¬í˜„ë¨

## ì˜ëª»ëœ ì½”ë“œ (Before)

### `ssi_silog_loss.py` Line 124-132
```python
# âŒ WRONG: Multiplies by ratio at the end
log_pred = torch.log(pred_depth_masked * self.silog_ratio)  # * 10
log_gt = torch.log(gt_depth_masked * self.silog_ratio)      # * 10
log_diff = log_pred - log_gt
silog1 = torch.mean(log_diff ** 2)
silog2 = self.silog_ratio2 * (log_diff.mean() ** 2)
silog_var = silog1 - silog2
silog_loss = torch.sqrt(silog_var + 1e-8) * self.silog_ratio  # âŒ * 10 AGAIN!
```

### `supervised_loss.py` Line 72-79
```python
# âŒ WRONG: Same issue
log_diff = torch.log(pred * self.ratio) - torch.log(gt * self.ratio)
silog1 = torch.mean(log_diff ** 2)
silog2 = self.ratio2 * (log_diff.mean() ** 2)
silog_loss = torch.sqrt(silog1 - silog2) * self.ratio  # âŒ * 10!
```

## ìˆ˜í•™ì  ë¶„ì„

### ì›ë³¸ Silog ê³µì‹ (ë…¼ë¬¸)
```
Silog = sqrt(E[d^2] - Î» * E[d]^2)
where d = log(pred) - log(gt)
      Î» = 0.85
```

### ì˜ëª»ëœ êµ¬í˜„ì˜ ë¬¸ì œ
```python
# Step 1: log(pred * 10) - log(gt * 10)
#       = log(pred) + log(10) - log(gt) - log(10)
#       = log(pred) - log(gt)  â† ì´ ë¶€ë¶„ì€ OK (log íŠ¹ì„±ìƒ ìƒì‡„)

# Step 2: sqrt(E[d^2] - Î» * E[d]^2) * 10  â† âŒ ë¬¸ì œ!
#       Lossê°€ 10ë°°ë¡œ ì¦í­ë¨!
```

**ê²°ê³¼**: 
- Silog Loss â‰ˆ 0.1~0.2 â†’ **1.0~2.0**ìœ¼ë¡œ ì¦í­
- SSI Loss weight = 0.7, Silog weight = 0.3ì´ë¯€ë¡œ
- Total Loss = 0.7 * SSI + 0.3 * (Silog * 10)
- Silog componentê°€ ì§€ë°°ì ì´ ë˜ì–´ í•™ìŠµ ë¶ˆì•ˆì •

## ì˜¬ë°”ë¥¸ ì½”ë“œ (After)

### `ssi_silog_loss.py` (Fixed)
```python
# âœ… CORRECT: No multiplicative scaling
log_pred = torch.log(pred_depth_masked)
log_gt = torch.log(gt_depth_masked)
log_diff = log_pred - log_gt
silog1 = torch.mean(log_diff ** 2)
silog2 = self.silog_ratio2 * (log_diff.mean() ** 2)
silog_var = silog1 - silog2
silog_loss = torch.sqrt(silog_var + 1e-8)  # âœ… No * ratio!
```

### `supervised_loss.py` (Fixed)
```python
# âœ… CORRECT
log_diff = torch.log(pred) - torch.log(gt)
silog1 = torch.mean(log_diff ** 2)
silog2 = self.ratio2 * (log_diff.mean() ** 2)
silog_loss = torch.sqrt(silog1 - silog2)  # âœ… No * ratio!
```

## ì˜ˆìƒ íš¨ê³¼

### Before (ì˜ëª»ë¨):
- Loss: 1.42~1.45 (ë©ˆì¶¤)
- Silog component: ~1.0~1.5
- Gradient: ë¶ˆì•ˆì • (ë„ˆë¬´ í¼)

### After (ì˜¬ë°”ë¦„):
- Loss: ~0.15~0.25 ì˜ˆìƒ
- Silog component: ~0.1~0.2
- Gradient: ì•ˆì •ì 
- í•™ìŠµ ì •ìƒ ì§„í–‰ ì˜ˆìƒ

## ì°¸ê³  ë¬¸í—Œ

Original Silog Loss paper:
```
Eigen et al., "Depth Map Prediction from a Single Image using a Multi-Scale Deep Network"
Loss = sqrt(1/n * Î£(log d_i)^2 - Î»/n^2 * (Î£ log d_i)^2)
where d_i = log(pred_i) - log(gt_i)
```

## ìˆ˜ì • ì¼ì‹œ

- 2025.10.28
- Files: `ssi_silog_loss.py`, `supervised_loss.py`
- Reason: Lossê°€ 1.42~1.45ì—ì„œ ë©ˆì¶°ì„œ ë¶„ì„ í›„ ë°œê²¬
