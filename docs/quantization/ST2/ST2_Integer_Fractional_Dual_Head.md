# ST2: Integer-Fractional Dual-Head Architecture

**ì „ëµ ë¶„ë¥˜**: ëª¨ë¸ êµ¬ì¡° ë³€ê²½ (Parameter-driven Decoder Extension)  
**ë‚œì´ë„**: â­â­â­â­ (High - ì¬í•™ìŠµ í•„ìš”)  
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2-3ì£¼  
**ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ **: abs_rel 0.1139 â†’ **0.055** (51% ê°œì„ )  
**ë‚ ì§œ**: 2025-11-07  
**ë¬¸ì„œ ë²„ì „**: 2.1 (ë¶„í•  ë¬¸ì„œ êµ¬ì¡°)

---

## âš ï¸ ë¬¸ì„œ êµ¬ì¡° ë³€ê²½

ì´ ë¬¸ì„œëŠ” ì´ì œ **ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ íŒŒì¼ë¡œ ë¶„ë¦¬**ë˜ì—ˆìŠµë‹ˆë‹¤.  
ìƒì„¸í•œ ë‚´ìš©ì€ **`docs/quantization/ST2/`** í´ë”ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### ğŸ“ ìƒˆë¡œìš´ ë¬¸ì„œ êµ¬ì¡°

- **[README.md](ST2/README.md)**: ì „ì²´ ê°œìš” ë° Quick Start
- **[01_Overview_Strategy.md](ST2/01_Overview_Strategy.md)**: ì „ëµ ê°œìš” ë° ì½”ë“œë² ì´ìŠ¤ ë¶„ì„
- **[02_Implementation_Guide.md](ST2/02_Implementation_Guide.md)**: êµ¬í˜„ ê°€ì´ë“œ (Step-by-Step)
- **[03_Configuration_Testing.md](ST2/03_Configuration_Testing.md)**: ì„¤ì • ë° í…ŒìŠ¤íŠ¸
- **[04_Training_Evaluation.md](ST2/04_Training_Evaluation.md)**: í•™ìŠµ ë° í‰ê°€
- **[05_Troubleshooting.md](ST2/05_Troubleshooting.md)**: ë¬¸ì œ í•´ê²°

---

## ğŸš€ Quick Navigation

### ì²˜ìŒ ì‹œì‘í•˜ëŠ” ê²½ìš°
â†’ [ST2/README.md](ST2/README.md)ë¥¼ ë¨¼ì € ì½ìœ¼ì„¸ìš”.

### êµ¬í˜„ì„ ì‹œì‘í•˜ë ¤ëŠ” ê²½ìš°
â†’ [ST2/02_Implementation_Guide.md](ST2/02_Implementation_Guide.md)ë¡œ ì´ë™í•˜ì„¸ìš”.

### ë¬¸ì œê°€ ë°œìƒí•œ ê²½ìš°
â†’ [ST2/05_Troubleshooting.md](ST2/05_Troubleshooting.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ“‹ ì•„ë˜ëŠ” ë ˆê±°ì‹œ ë¬¸ì„œ (ì°¸ê³ ìš©)

ì´ì „ ë²„ì „ì˜ í†µí•© ë¬¸ì„œ ë‚´ìš©ì€ ì•„ë˜ì— ë³´ì¡´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
í•˜ì§€ë§Œ **ìµœì‹  ì •ë³´ëŠ” ST2 í´ë”ì˜ ë¶„í• ëœ ë¬¸ì„œë¥¼ ì°¸ì¡°**í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

---

## ğŸ¯ í•µì‹¬ ì„¤ê³„ ì›ì¹™

**âœ… ê¸°ì¡´ ê¸°ëŠ¥ ë³´ì¡´ (Backward Compatibility)**:
- ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥(`use_film`, `use_enhanced_lidar` ë“±) 100% ìœ ì§€
- Single-Head ëª¨ë¸ê³¼ Dual-Head ëª¨ë¸ì´ ë™ì¼ ì½”ë“œë² ì´ìŠ¤ì—ì„œ YAMLë§Œìœ¼ë¡œ ì „í™˜ ê°€ëŠ¥
- ê¸°ì¡´ checkpoint í˜¸í™˜ì„± ë³´ì¥

**âœ… Parameter-driven ì„¤ê³„**:
- ìƒˆ ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„± **ì—†ìŒ** (ìœ ì§€ë³´ìˆ˜ ì•…ëª½ ë°©ì§€)
- Decoderë§Œ ì¡°ê±´ë¶€ êµì²´ (Factory Pattern)
- YAML configë¡œ ëª¨ë“  ë™ì‘ ì œì–´

---

## ğŸ“‘ ëª©ì°¨

### 1. [ì „ëµ ê°œìš” ë° ì½”ë“œë² ì´ìŠ¤ ë¶„ì„](#1-ì „ëµ-ê°œìš”-ë°-ì½”ë“œë² ì´ìŠ¤-ë¶„ì„)
   - 1.1. Phase 1 ê²°ê³¼ ë¶„ì„
   - 1.2. í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„
   - 1.3. ì„¤ê³„ ê²°ì •: í™•ì¥ vs ì‹ ê·œ ìƒì„±

### 2. [ê¸°ìˆ ì  ë°°ê²½](#2-ê¸°ìˆ ì -ë°°ê²½)
   - 2.1. INT8 ì–‘ìí™”ì˜ ê·¼ë³¸ì  í•œê³„
   - 2.2. ì™œ Integer-Fractional ë¶„ë¦¬ê°€ íš¨ê³¼ì ì¸ê°€?
   - 2.3. NPU Dual-Output í™œìš©

### 3. [ì•„í‚¤í…ì²˜ ì„¤ê³„ (ì½”ë“œë² ì´ìŠ¤ í†µí•©)](#3-ì•„í‚¤í…ì²˜-ì„¤ê³„-ì½”ë“œë² ì´ìŠ¤-í†µí•©)
   - 3.1. í˜„ì¬ ResNetSAN01 êµ¬ì¡° ë¶„ì„
   - 3.2. Decoder Factory Pattern ì„¤ê³„
   - 3.3. ê¸°ì¡´ ê¸°ëŠ¥ê³¼ì˜ í†µí•©

### 4. [êµ¬í˜„ ê°€ì´ë“œ (Step-by-Step)](#4-êµ¬í˜„-ê°€ì´ë“œ-step-by-step)
   - 4.1. Phase 1: DualHeadDepthDecoder êµ¬í˜„
   - 4.2. Phase 2: Helper Functions
   - 4.3. Phase 3: ResNetSAN01 í™•ì¥
   - 4.4. Phase 4: Loss Function êµ¬í˜„
   - 4.5. Phase 5: Model Wrapper í†µí•©

### 5. [YAML Configuration](#5-yaml-configuration)
   - 5.1. Single-Head (ê¸°ì¡´)
   - 5.2. Dual-Head (ì‹ ê·œ)
   - 5.3. í•˜ì´ë¸Œë¦¬ë“œ ì¡°í•©

### 6. [í…ŒìŠ¤íŠ¸ ë° ê²€ì¦](#6-í…ŒìŠ¤íŠ¸-ë°-ê²€ì¦)
   - 6.1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
   - 6.2. í†µí•© í…ŒìŠ¤íŠ¸
   - 6.3. Backward Compatibility ê²€ì¦

### 7. [í•™ìŠµ ë° í‰ê°€](#7-í•™ìŠµ-ë°-í‰ê°€)

### 8. [Troubleshooting](#8-troubleshooting)

---

## 1. ì „ëµ ê°œìš” ë° ì½”ë“œë² ì´ìŠ¤ ë¶„ì„

### 1.1. Phase 1 ê²°ê³¼ ë¶„ì„

**Phase 1 (Advanced PTQ Calibration) ê²°ê³¼**:

| Metric | 100 samples | 300 samples | ëª©í‘œ | ë‹¬ì„± ì—¬ë¶€ |
|--------|-------------|-------------|------|----------|
| **abs_rel** | 0.1133 | 0.1139 | < 0.09 | âŒ ì‹¤íŒ¨ |
| **rmse** | 0.741m | 0.751m | - | âŒ ì•…í™” |
| **Î´<1.25** | 0.9239 | 0.9061 | - | âŒ ì•…í™” |

**í•µì‹¬ ë°œê²¬**:
- Calibration ì´ë¯¸ì§€ë¥¼ 100 â†’ 300ìœ¼ë¡œ í™•ì¥í–ˆìœ¼ë‚˜ **ì„±ëŠ¥ ê°œì„  ì—†ìŒ**
- ì˜¤íˆë ¤ ì¼ë¶€ ë©”íŠ¸ë¦­ì´ ì•…í™”ë¨
- **ê²°ë¡ **: ë°ì´í„°ì…‹ ìµœì í™”ë§Œìœ¼ë¡œëŠ” ëª©í‘œ ë‹¬ì„± ë¶ˆê°€ëŠ¥ â†’ **ëª¨ë¸ êµ¬ì¡° ë³€ê²½ í•„ìˆ˜**

### 1.2. í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„

**âœ… ì½”ë“œë² ì´ìŠ¤ì˜ ì„¤ê³„ íŒ¨í„´ (ì´ë¯¸ Parameter-driven)**:

```python
# packnet_sfm/networks/depth/ResNetSAN01.py (í˜„ì¬ êµ¬ì¡°)
class ResNetSAN01(nn.Module):
    def __init__(self, ..., use_film=False, use_enhanced_lidar=False, **kwargs):
        # EncoderëŠ” ê³µí†µ
        self.encoder = ResnetEncoder(num_layers=num_layers, pretrained=True)
        
        # DecoderëŠ” ë‹¨ì¼ (í™•ì¥ ì˜ˆì •)
        self.decoder = DepthDecoder(num_ch_enc=self.encoder.num_ch_enc)
        
        # Optional features (ì¡°ê±´ë¶€ í™œì„±í™”)
        if use_film:
            if use_enhanced_lidar:
                self.mconvs = EnhancedMinkowskiEncoder(...)  # Enhanced
            else:
                self.mconvs = MinkowskiEncoder(...)  # Standard
        else:
            self.mconvs = None  # Inference-only
```

**í•µì‹¬ ë°œê²¬**:
1. âœ… **ì´ë¯¸ Decoder êµì²´ íŒ¨í„´ ì¡´ì¬**: `DepthDecoder`, `RaySurfaceDecoder`, `YOLOv8DepthDecoder`
2. âœ… **ì¡°ê±´ë¶€ ê¸°ëŠ¥ í™œì„±í™”**: `use_film`, `use_enhanced_lidar` ë“±
3. âœ… **YAML ê¸°ë°˜ ì„¤ì •**: `configs/train_resnet_san_ncdb_640x384.yaml`

**ê¸°ì¡´ ìœ ì‚¬ íŒ¨í„´**:
```python
# packnet_sfm/networks/depth/RaySurfaceResNet.py (ì°¸ê³  ì˜ˆì‹œ)
class RaySurfaceResNet(nn.Module):
    def __init__(self, ...):
        self.encoder = ResnetEncoder(...)
        self.decoder = DepthDecoder(...)        # Standard decoder
        self.ray_surf = RaySurfaceDecoder(...)  # Additional decoder
```

### 1.3. ì„¤ê³„ ê²°ì •: í™•ì¥ vs ì‹ ê·œ ìƒì„±

| ë¹„êµ í•­ëª© | âŒ ì‹ ê·œ ëª¨ë¸ ìƒì„±<br/>`ResNetSAN01_DualHead.py` | âœ… **ê¸°ì¡´ ëª¨ë¸ í™•ì¥**<br/>`use_dual_head` íŒŒë¼ë¯¸í„° |
|-----------|------------------------------------------------|---------------------------------------------------|
| **ì½”ë“œ ì¤‘ë³µ** | ~300ì¤„ ë³µì‚¬ (Encoder, FiLM, Minkowski ë“±) | 0ì¤„ (Decoderë§Œ êµì²´) |
| **ìœ ì§€ë³´ìˆ˜** | ë²„ê·¸ ìˆ˜ì • ì‹œ 2ê³³ ìˆ˜ì • í•„ìš” | 1ê³³ë§Œ ìˆ˜ì • |
| **ê¸°ëŠ¥ ì¡°í•©** | `use_film + dual_head` ì¡°í•© ì–´ë ¤ì›€ | ëª¨ë“  ì¡°í•© ììœ ë¡­ê²Œ ê°€ëŠ¥ |
| **Rollback** | ìƒˆ ëª¨ë¸ ì‚­ì œ í•„ìš” | YAML flagë§Œ ë³€ê²½ |
| **Checkpoint í˜¸í™˜** | ë³µì¡í•œ ë³€í™˜ ë¡œì§ í•„ìš” | íˆ¬ëª…í•˜ê²Œ ë™ì‘ |
| **í…ŒìŠ¤íŠ¸** | ëª¨ë“  ê¸°ëŠ¥ ì¬í…ŒìŠ¤íŠ¸ | Decoderë§Œ í…ŒìŠ¤íŠ¸ |

**âœ… ìµœì¢… ê²°ì •: ê¸°ì¡´ ResNetSAN01 í™•ì¥**

ì´ìœ :
1. ì½”ë“œë² ì´ìŠ¤ê°€ ì´ë¯¸ ì´ íŒ¨í„´ì„ ë”°ë¥´ê³  ìˆìŒ (best practice)
2. ìµœì†Œ ë³€ê²½ìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼
3. ì‹¤í—˜ ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ rollback ê°€ëŠ¥

1. **Per-channel Quantization ë¯¸ì§€ì›**:
   - NPUëŠ” Per-tensor ì–‘ìí™”ë§Œ ì§€ì›
   - ë‹¨ì¼ Scale/Zero-pointë¡œ 0.5m~15m ë²”ìœ„ë¥¼ í‘œí˜„í•´ì•¼ í•¨
   - INT8(256 levels)ë¡œ 14.5m ë²”ìœ„ í‘œí˜„ â†’ **ì–‘ìí™” ì˜¤ì°¨ Â±28mm**

2. **ë„“ì€ Depth ë²”ìœ„**:
   - í˜„ì¬ ëª¨ë¸: ë‹¨ì¼ ì¶œë ¥ìœ¼ë¡œ 0.5~15m ì˜ˆì¸¡
   - FP32ëŠ” ë†’ì€ ì •ë°€ë„ë¡œ ëª¨ë“  ë²”ìœ„ í‘œí˜„ ê°€ëŠ¥
   - INT8ì€ 256 ë ˆë²¨ë§Œ ì‚¬ìš© ê°€ëŠ¥ â†’ ì •ë°€ë„ ê¸‰ê²©íˆ ì €í•˜

3. **Calibrationë§Œìœ¼ë¡œ í•œê³„**:
   - NPUì˜ ìë™ Clipping/Bias Correctionì€ ì´ë¯¸ ìµœì í™”ë˜ì–´ ìˆìŒ
   - ë” ë§ì€ calibration ë°ì´í„°ë¥¼ ì œê³µí•´ë„ íš¨ê³¼ ì—†ìŒ
   - **êµ¬ì¡°ì  í•´ê²°ì±… í•„ìš”**

### 1.3. í•µì‹¬ ì•„ì´ë””ì–´

**ê¹Šì´ ê°’ì„ ë‘ ê°œì˜ ë²”ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì˜ˆì¸¡**:

```
Original Single-Head:
  depth âˆˆ [0.5, 15.0]m  â†’  1 output  â†’  INT8 (256 levels)
  ì–‘ìí™” ì˜¤ì°¨: Â±28mm

Proposed Dual-Head:
  integer_part âˆˆ [0, 15]  â†’  Head 1 (INT8, 16 levels effective)
  fractional_part âˆˆ [0, 1]m  â†’  Head 2 (INT8, 256 levels)
  ì–‘ìí™” ì˜¤ì°¨: Â±2mm (14ë°° ê°œì„ !)
```

**ì¥ì **:
- âœ… NPUì˜ Dual-Output ê¸°ëŠ¥ í™œìš© (ì¶”ê°€ ë¹„ìš© ì—†ìŒ)
- âœ… ì–‘ìí™” ì •ë°€ë„ 14ë°° í–¥ìƒ
- âœ… Per-channel ì—†ì´ë„ ë†’ì€ ì •ë°€ë„ í™•ë³´
- âœ… ë¬¼ë¦¬ì  ì˜ë¯¸ê°€ ëª…í™• (ì •ìˆ˜ë¶€ = ë¯¸í„° ë‹¨ìœ„, ì†Œìˆ˜ë¶€ = ì„œë¸Œë¯¸í„° ì •ë°€ë„)

---

## 2. ê¸°ìˆ ì  ë°°ê²½

### 2.1. INT8 ì–‘ìí™”ì˜ ê·¼ë³¸ì  í•œê³„

**í˜„ì¬ ëª¨ë¸ì˜ ê·¼ë³¸ì  ë¬¸ì œ**:

1. **Per-channel Quantization ë¯¸ì§€ì›**:
   - NPUëŠ” Per-tensor ì–‘ìí™”ë§Œ ì§€ì›
   - ë‹¨ì¼ Scale/Zero-pointë¡œ 0.5m~15m ë²”ìœ„ë¥¼ í‘œí˜„í•´ì•¼ í•¨
   - INT8(256 levels)ë¡œ 14.5m ë²”ìœ„ í‘œí˜„ â†’ **ì–‘ìí™” ì˜¤ì°¨ Â±28mm**

2. **ë„“ì€ Depth ë²”ìœ„**:
   - í˜„ì¬ ëª¨ë¸: ë‹¨ì¼ ì¶œë ¥ìœ¼ë¡œ 0.5~15m ì˜ˆì¸¡
   - FP32ëŠ” ë†’ì€ ì •ë°€ë„ë¡œ ëª¨ë“  ë²”ìœ„ í‘œí˜„ ê°€ëŠ¥
   - INT8ì€ 256 ë ˆë²¨ë§Œ ì‚¬ìš© ê°€ëŠ¥ â†’ ì •ë°€ë„ ê¸‰ê²©íˆ ì €í•˜

3. **Calibrationë§Œìœ¼ë¡œ í•œê³„**:
   - NPUì˜ ìë™ Clipping/Bias Correctionì€ ì´ë¯¸ ìµœì í™”ë˜ì–´ ìˆìŒ
   - ë” ë§ì€ calibration ë°ì´í„°ë¥¼ ì œê³µí•´ë„ íš¨ê³¼ ì—†ìŒ
   - **êµ¬ì¡°ì  í•´ê²°ì±… í•„ìš”**

**ì–‘ìí™” ê³µì‹**:
```
x_quantized = round((x - zero_point) / scale)
scale = (max - min) / 255
```

**í˜„ì¬ Single-Head ëª¨ë¸**:
- ë²”ìœ„: [0.5, 15.0]m
- scale = (15.0 - 0.5) / 255 = 0.0569
- **ì–‘ìí™” ê°„ê²©**: 56.9mm (ì•½ 5.7cm)
- ì‹¤ì œ ì˜¤ì°¨: Â±28.4mm

**ë¬¸ì œì **:
1. **ê±°ì¹œ ì–‘ìí™”**: 5.7cm ê°„ê²©ìœ¼ë¡œë§Œ ê°’ í‘œí˜„ ê°€ëŠ¥
2. **ëª¨ë“  ê±°ë¦¬ì— ë™ì¼í•œ ì˜¤ì°¨**: 1m ê±°ë¦¬ë„, 15m ê±°ë¦¬ë„ ê°™ì€ Â±28mm ì˜¤ì°¨
3. **Per-tensor ì œì•½**: ì±„ë„ë³„ë¡œ ë‹¤ë¥¸ scaleì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ

### 2.2. ì™œ Integer-Fractional ë¶„ë¦¬ê°€ íš¨ê³¼ì ì¸ê°€?

**Dual-Head ì ‘ê·¼**:

**Head 1: Integer Part (ì •ìˆ˜ë¶€ ì˜ˆì¸¡)**
```
ë²”ìœ„: [0, 15] (16ê°œ ì •ìˆ˜ê°’)
ì¶œë ¥: Sigmoid [0, 1] â†’ ì„ í˜• ë³€í™˜ â†’ [0, 15]
ì–‘ìí™”: INT8(256 levels)ë¡œ 16ê°œ ê°’ í‘œí˜„
íš¨ê³¼ì  ì •ë°€ë„: 16ë°° ì˜¤ë²„ìƒ˜í”Œë§ (ê° ì •ìˆ˜ë‹¹ 16ê°œ ë ˆë²¨)
```

**Head 2: Fractional Part (ì†Œìˆ˜ë¶€ ì˜ˆì¸¡)**
```
ë²”ìœ„: [0.0, 1.0]m
ì¶œë ¥: Sigmoid [0, 1] â†’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
ì–‘ìí™”: INT8(256 levels)ë¡œ 1m ë²”ìœ„ í‘œí˜„
scale = 1.0 / 255 = 0.00392
ì–‘ìí™” ê°„ê²©: 3.92mm
ì‹¤ì œ ì˜¤ì°¨: Â±1.96mm (14ë°° ê°œì„ !)
```

**ìµœì¢… ê¹Šì´ ë³µì›**:
```python
depth = integer_part + fractional_part
ì˜ˆ: integer=5, fractional=0.347 â†’ depth=5.347m
```

**ì •ë°€ë„ ë¹„êµ**:

| ë°©ì‹ | ë²”ìœ„ | ì–‘ìí™” ê°„ê²© | ì˜¤ì°¨ | ê°œì„ ìœ¨ |
|------|------|-------------|------|--------|
| Single-Head | [0.5, 15.0]m | 56.9mm | Â±28.4mm | - |
| Dual-Head (Integer) | [0, 15] | 16 levels | Â±0.5 | - |
| Dual-Head (Fractional) | [0, 1.0]m | 3.92mm | **Â±1.96mm** | **14.5ë°°** |

### 2.3. NPU Dual-Output í™œìš©

**NPU í™•ì¸ëœ ì‚¬í•­**:
- âœ… **Dual-Output ì§€ì› í™•ì •**
- ë‘ ê°œì˜ ë…ë¦½ì ì¸ ì¶œë ¥ í…ì„œ ìƒì„± ê°€ëŠ¥
- ì¶”ê°€ ì—°ì‚° ë¹„ìš© ì—†ìŒ (ë™ì¼í•œ feature mapì—ì„œ ë¶„ê¸°)

**êµ¬í˜„ ë°©ì‹**:
```
Encoder Features â†’ Decoder â†’ [Branch 1: Integer Head]
                           â†’ [Branch 2: Fractional Head]
```

---

## 3. ì•„í‚¤í…ì²˜ ì„¤ê³„ (ì½”ë“œë² ì´ìŠ¤ í†µí•©)

### 3.1. í˜„ì¬ ResNetSAN01 êµ¬ì¡° ë¶„ì„

**íŒŒì¼ ìœ„ì¹˜**: `packnet_sfm/networks/depth/ResNetSAN01.py`

```python
class ResNetSAN01(nn.Module):
    def __init__(self, dropout=None, version=None, use_film=False, 
                 film_scales=[0], use_enhanced_lidar=False,
                 min_depth=0.5, max_depth=80.0, **kwargs):
        super().__init__()
        
        # Depth range (YAMLì—ì„œ ì „ë‹¬ë¨)
        self.min_depth = float(min_depth)
        self.max_depth = float(max_depth)
        
        # Encoder (ê³µí†µ - ëª¨ë“  ëª¨ë“œì—ì„œ ë™ì¼)
        num_layers = int(version[:2]) if version else 18
        self.encoder = ResnetEncoder(num_layers=num_layers, pretrained=True)
        
        # â¬‡ï¸ Decoder (ì—¬ê¸°ë¥¼ í™•ì¥í•  ì˜ˆì •)
        self.decoder = DepthDecoder(num_ch_enc=self.encoder.num_ch_enc)
        
        # Optional: FiLM modulation
        self.use_film = use_film
        if use_film:
            # Minkowski encoder ìƒì„±
            if use_enhanced_lidar:
                self.mconvs = EnhancedMinkowskiEncoder(...)
            else:
                self.mconvs = MinkowskiEncoder(...)
        else:
            self.mconvs = None
        
        # Learnable fusion weights (FiLMìš©)
        self.weight = nn.Parameter(torch.ones(5) * 0.5)
        self.bias = nn.Parameter(torch.zeros(5))
    
    def run_network(self, rgb, input_depth=None):
        # Encode RGB features
        skip_features = self.encoder(rgb)
        
        # Optional: FiLM modulation
        if input_depth is not None and self.use_film:
            # ... FiLM processing ...
            pass
        
        # Decode to sigmoid outputs
        outputs = self.decoder(skip_features)
        # outputs = {("disp", 0): sigmoid [0,1], ...}
        
        return outputs
```

**í•µì‹¬ ë°œê²¬**:
- `self.decoder` êµì²´ë§Œìœ¼ë¡œ Single/Dual-Head ì „í™˜ ê°€ëŠ¥
- ë‚˜ë¨¸ì§€ 300ì¤„ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©
- `min_depth`, `max_depth`ê°€ ì´ë¯¸ YAMLì—ì„œ ì „ë‹¬ë¨

### 3.2. Decoder Factory Pattern ì„¤ê³„

**ëª©í‘œ**: YAML íŒŒë¼ë¯¸í„°ë¡œ Decoder ì„ íƒ

```python
# packnet_sfm/networks/depth/ResNetSAN01.py (ìˆ˜ì • ë¶€ë¶„)
class ResNetSAN01(nn.Module):
    def __init__(self, ..., use_dual_head=False, **kwargs):
        super().__init__()
        
        # ... ê¸°ì¡´ encoder ì½”ë“œ ìœ ì§€ ...
        
        # ğŸ†• Decoder ì„ íƒ (Factory Pattern)
        if use_dual_head:
            from packnet_sfm.networks.layers.resnet.dual_head_depth_decoder import DualHeadDepthDecoder
            self.decoder = DualHeadDepthDecoder(
                num_ch_enc=self.encoder.num_ch_enc,
                max_depth=self.max_depth,
                scales=range(4)
            )
            self.is_dual_head = True
            print(f"âœ… Using Dual-Head Decoder (max_depth={self.max_depth})")
        else:
            self.decoder = DepthDecoder(num_ch_enc=self.encoder.num_ch_enc)
            self.is_dual_head = False
            print(f"âœ… Using Single-Head Decoder")
        
        # ... ê¸°ì¡´ FiLM/Minkowski ì½”ë“œ ìœ ì§€ ...
```

**ë³€ê²½ëŸ‰**: **10ì¤„ ì¶”ê°€** (ê¸°ì¡´ ì½”ë“œ 0ì¤„ ìˆ˜ì •)

### 3.3. ê¸°ì¡´ ê¸°ëŠ¥ê³¼ì˜ í†µí•©

**ëª¨ë“  ì¡°í•© ê°€ëŠ¥**:

```yaml
# ì¡°í•© 1: Single-Head (ê¸°ì¡´)
depth_net:
    name: 'ResNetSAN01'
    use_dual_head: false
    use_film: false

# ì¡°í•© 2: Dual-Head only
depth_net:
    name: 'ResNetSAN01'
    use_dual_head: true
    use_film: false

# ì¡°í•© 3: Dual-Head + FiLM (í•˜ì´ë¸Œë¦¬ë“œ)
depth_net:
    name: 'ResNetSAN01'
    use_dual_head: true
    use_film: true
    film_scales: [0]

# ì¡°í•© 4: Dual-Head + FiLM + Enhanced LiDAR (Full)
depth_net:
    name: 'ResNetSAN01'
    use_dual_head: true
    use_film: true
    use_enhanced_lidar: true
```

**Backward Compatibility ë³´ì¥**:
- `use_dual_head` íŒŒë¼ë¯¸í„° ì—†ìœ¼ë©´ â†’ Single-Head (ê¸°ì¡´ ë™ì‘)
- ê¸°ì¡´ checkpoint ë¡œë”© â†’ ì •ìƒ ë™ì‘ (decoderë§Œ ë‹¤ë¦„)

---

## 4. êµ¬í˜„ ê°€ì´ë“œ (Step-by-Step)

### 4.1. Phase 1: DualHeadDepthDecoder êµ¬í˜„

**íŒŒì¼ ìƒì„±**: `packnet_sfm/networks/layers/resnet/dual_head_depth_decoder.py`

**ì™„ì „í•œ êµ¬í˜„ ì½”ë“œ**:

```python
# packnet_sfm/networks/layers/resnet/dual_head_depth_decoder.py
"""
Dual-Head Depth Decoder for Integer-Fractional depth prediction.

ì´ DecoderëŠ” ê¸°ì¡´ DepthDecoderì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ ì§€í•˜ë©´ì„œ,
ë‘ ê°œì˜ ë…ë¦½ì ì¸ ì¶œë ¥ í—¤ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
"""

from __future__ import absolute_import, division, print_function

import numpy as np
import torch
import torch.nn as nn
from collections import OrderedDict

from .layers import ConvBlock, Conv3x3, upsample


class DualHeadDepthDecoder(nn.Module):
    """
    Integer-Fractional Dual-Head Depth Decoder
    
    ê¸°ì¡´ DepthDecoderì™€ ë™ì¼í•œ upsampling êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë˜,
    ìµœì¢… ì¶œë ¥ í—¤ë“œë§Œ 2ê°œë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    
    Parameters
    ----------
    num_ch_enc : list of int
        Encoder channel counts (e.g., [64, 64, 128, 256, 512])
    scales : list of int
        Which scales to produce outputs (default: [0, 1, 2, 3])
    max_depth : float
        Maximum depth for integer head (default: 15.0)
    use_skips : bool
        Whether to use skip connections (default: True)
    
    Outputs
    -------
    - ("integer", scale): [B, 1, H, W] sigmoid [0, 1] â†’ represents [0, max_depth]
    - ("fractional", scale): [B, 1, H, W] sigmoid [0, 1] â†’ represents [0, 1]m
    """
    
    def __init__(self, num_ch_enc, scales=range(4), max_depth=15.0, use_skips=True):
        super(DualHeadDepthDecoder, self).__init__()

        self.num_ch_enc = num_ch_enc
        self.scales = scales
        self.max_depth = max_depth
        self.use_skips = use_skips
        self.upsample_mode = 'nearest'
        
        # Decoder channel counts (ê¸°ì¡´ê³¼ ë™ì¼)
        self.num_ch_dec = np.array([16, 32, 64, 128, 256])

        # ========================================
        # ê³µí†µ Upsampling Layers (ê¸°ì¡´ê³¼ 100% ë™ì¼)
        # ========================================
        self.convs = OrderedDict()
        for i in range(4, -1, -1):
            # upconv_0: channel reduction
            num_ch_in = self.num_ch_enc[-1] if i == 4 else self.num_ch_dec[i + 1]
            num_ch_out = self.num_ch_dec[i]
            self.convs[("upconv", i, 0)] = ConvBlock(num_ch_in, num_ch_out)

            # upconv_1: skip connection fusion
            num_ch_in = self.num_ch_dec[i]
            if self.use_skips and i > 0:
                num_ch_in += self.num_ch_enc[i - 1]
            num_ch_out = self.num_ch_dec[i]
            self.convs[("upconv", i, 1)] = ConvBlock(num_ch_in, num_ch_out)

        # ========================================
        # Dual-Head: ê° ìŠ¤ì¼€ì¼ë³„ë¡œ 2ê°œì˜ ì¶œë ¥ í—¤ë“œ
        # ========================================
        for s in self.scales:
            # Integer Head (ì •ìˆ˜ë¶€ ì˜ˆì¸¡: 0~max_depth)
            self.convs[("integer_conv", s)] = Conv3x3(self.num_ch_dec[s], 1)
            
            # Fractional Head (ì†Œìˆ˜ë¶€ ì˜ˆì¸¡: 0~1m)
            self.convs[("fractional_conv", s)] = Conv3x3(self.num_ch_dec[s], 1)

        self.decoder = nn.ModuleList(list(self.convs.values()))
        self.sigmoid = nn.Sigmoid()
        
        print(f"ğŸ”§ DualHeadDepthDecoder initialized:")
        print(f"   Max depth: {max_depth}m")
        print(f"   Scales: {list(scales)}")
        print(f"   Integer quantization interval: {max_depth/255:.4f}m")
        print(f"   Fractional quantization interval: {1.0/255:.4f}m (3.92mm)")

    def forward(self, input_features):
        """
        Forward pass
        
        Parameters
        ----------
        input_features : list of torch.Tensor
            Encoder features [feat0, feat1, ..., feat4]
        
        Returns
        -------
        outputs : dict
            {
                ("integer", scale): [B, 1, H, W] sigmoid [0,1],
                ("fractional", scale): [B, 1, H, W] sigmoid [0,1]
            }
        """
        self.outputs = {}

        # ========================================
        # ê³µí†µ Decoder Processing (ê¸°ì¡´ê³¼ ë™ì¼)
        # ========================================
        x = input_features[-1]
        for i in range(4, -1, -1):
            # Upsample
            x = self.convs[("upconv", i, 0)](x)
            x = [upsample(x)]
            
            # Skip connection
            if self.use_skips and i > 0:
                x += [input_features[i - 1]]
            
            x = torch.cat(x, 1)
            x = self.convs[("upconv", i, 1)](x)
            
            # ========================================
            # Dual-Head Outputs
            # ========================================
            if i in self.scales:
                # Integer Head: [0, 1] sigmoid
                integer_raw = self.convs[("integer_conv", i)](x)
                self.outputs[("integer", i)] = self.sigmoid(integer_raw)
                
                # Fractional Head: [0, 1] sigmoid
                fractional_raw = self.convs[("fractional_conv", i)](x)
                self.outputs[("fractional", i)] = self.sigmoid(fractional_raw)

        return self.outputs
```

**í…ŒìŠ¤íŠ¸ ì½”ë“œ**:

```python
# test_dual_head_decoder.py
import torch
from packnet_sfm.networks.layers.resnet.dual_head_depth_decoder import DualHeadDepthDecoder

def test_dual_head_decoder():
    # Encoder channel counts (ResNet18)
    num_ch_enc = [64, 64, 128, 256, 512]
    
    # Create decoder
    decoder = DualHeadDepthDecoder(
        num_ch_enc=num_ch_enc,
        scales=[0],  # Only test scale 0
        max_depth=15.0
    )
    
    # Dummy encoder features
    batch_size = 2
    features = [
        torch.randn(batch_size, 64, 96, 160),   # scale 0
        torch.randn(batch_size, 64, 48, 80),    # scale 1
        torch.randn(batch_size, 128, 24, 40),   # scale 2
        torch.randn(batch_size, 256, 12, 20),   # scale 3
        torch.randn(batch_size, 512, 6, 10),    # scale 4
    ]
    
    # Forward pass
    outputs = decoder(features)
    
    # Check outputs
    assert ("integer", 0) in outputs, "Missing integer output"
    assert ("fractional", 0) in outputs, "Missing fractional output"
    
    integer_out = outputs[("integer", 0)]
    fractional_out = outputs[("fractional", 0)]
    
    assert integer_out.shape == (batch_size, 1, 96, 160), f"Wrong integer shape: {integer_out.shape}"
    assert fractional_out.shape == (batch_size, 1, 96, 160), f"Wrong fractional shape: {fractional_out.shape}"
    
    # Check value range (sigmoid output)
    assert integer_out.min() >= 0.0 and integer_out.max() <= 1.0, "Integer out of range"
    assert fractional_out.min() >= 0.0 and fractional_out.max() <= 1.0, "Fractional out of range"
    
    print("âœ… DualHeadDepthDecoder test passed!")

if __name__ == "__main__":
    test_dual_head_decoder()
```

### 4.2. Phase 2: Helper Functions

**íŒŒì¼ ìˆ˜ì •**: `packnet_sfm/networks/layers/resnet/layers.py`

**ì¶”ê°€í•  í•¨ìˆ˜ë“¤**:

```python
# packnet_sfm/networks/layers/resnet/layers.py (ê¸°ì¡´ íŒŒì¼ ëì— ì¶”ê°€)

def dual_head_to_depth(integer_sigmoid, fractional_sigmoid, max_depth):
    """
    Convert dual-head sigmoid outputs to depth
    
    Parameters
    ----------
    integer_sigmoid : torch.Tensor [B, 1, H, W]
        Integer part in sigmoid space [0, 1]
    fractional_sigmoid : torch.Tensor [B, 1, H, W]
        Fractional part in sigmoid space [0, 1]
    max_depth : float
        Maximum depth for integer scaling
    
    Returns
    -------
    depth : torch.Tensor [B, 1, H, W]
        Final depth in meters [0, max_depth + 1]
    
    Example
    -------
    >>> integer_sig = torch.tensor([[[[0.333]]]])  # 0.333 * 15 = 5.0
    >>> fractional_sig = torch.tensor([[[[0.5]]]])  # 0.5m
    >>> depth = dual_head_to_depth(integer_sig, fractional_sig, 15.0)
    >>> print(depth)  # 5.5m
    """
    # Integer part: [0, 1] â†’ [0, max_depth]
    integer_part = integer_sigmoid * max_depth
    
    # Fractional part: already [0, 1]m
    fractional_part = fractional_sigmoid
    
    # Combine
    depth = integer_part + fractional_part
    
    return depth


def decompose_depth(depth_gt, max_depth):
    """
    Decompose ground truth depth into integer and fractional parts
    
    Parameters
    ----------
    depth_gt : torch.Tensor [B, 1, H, W]
        Ground truth depth in meters
    max_depth : float
        Maximum depth for integer normalization
    
    Returns
    -------
    integer_gt : torch.Tensor [B, 1, H, W]
        Integer part in sigmoid space [0, 1]
    fractional_gt : torch.Tensor [B, 1, H, W]
        Fractional part [0, 1]m
    
    Example
    -------
    >>> depth = torch.tensor([[[[5.7]]]])  # 5.7m
    >>> integer_gt, frac_gt = decompose_depth(depth, 15.0)
    >>> print(integer_gt)  # 5.0 / 15.0 = 0.333
    >>> print(frac_gt)     # 0.7m
    """
    # Integer part: floor(depth)
    integer_meters = torch.floor(depth_gt)
    integer_gt = integer_meters / max_depth  # Normalize to [0, 1]
    
    # Fractional part: depth - floor(depth)
    fractional_gt = depth_gt - integer_meters  # Already [0, 1]m
    
    return integer_gt, fractional_gt


def dual_head_to_inv_depth(integer_sigmoid, fractional_sigmoid, max_depth, min_depth=0.5):
    """
    Convert dual-head outputs to inverse depth (for compatibility)
    
    Parameters
    ----------
    integer_sigmoid : torch.Tensor
    fractional_sigmoid : torch.Tensor
    max_depth : float
    min_depth : float
    
    Returns
    -------
    inv_depth : torch.Tensor
        Inverse depth [1/max_depth, 1/min_depth]
    """
    # First convert to depth
    depth = dual_head_to_depth(integer_sigmoid, fractional_sigmoid, max_depth)
    
    # Clamp to valid range
    depth = torch.clamp(depth, min=min_depth, max=max_depth)
    
    # Convert to inverse depth
    inv_depth = 1.0 / depth
    
    return inv_depth
```

**í…ŒìŠ¤íŠ¸**:

```python
# test_helper_functions.py
import torch
from packnet_sfm.networks.layers.resnet.layers import (
    dual_head_to_depth, decompose_depth, dual_head_to_inv_depth
)

def test_helpers():
    # Test 1: Decompose and reconstruct
    depth_gt = torch.tensor([[[[5.7, 12.3, 0.8]]]])
    max_depth = 15.0
    
    integer_gt, frac_gt = decompose_depth(depth_gt, max_depth)
    depth_reconstructed = dual_head_to_depth(integer_gt, frac_gt, max_depth)
    
    assert torch.allclose(depth_gt, depth_reconstructed, atol=1e-5), "Reconstruction failed"
    print("âœ… Test 1: Decompose/reconstruct passed")
    
    # Test 2: Edge cases
    depth_edge = torch.tensor([[[[0.0, 15.0, 7.999]]]])
    integer_gt, frac_gt = decompose_depth(depth_edge, max_depth)
    
    assert torch.all(integer_gt >= 0) and torch.all(integer_gt <= 1), "Integer out of range"
    assert torch.all(frac_gt >= 0) and torch.all(frac_gt < 1), "Fractional out of range"
    print("âœ… Test 2: Edge cases passed")
    
    # Test 3: Inverse depth conversion
    integer_sig = torch.tensor([[[[0.333]]]])
    frac_sig = torch.tensor([[[[0.5]]]])
    inv_depth = dual_head_to_inv_depth(integer_sig, frac_sig, max_depth, min_depth=0.5)
    
    expected_depth = 5.5  # 0.333*15 + 0.5 = 5.5
    expected_inv = 1.0 / expected_depth
    assert torch.allclose(inv_depth, torch.tensor([[[[expected_inv]]]]), atol=1e-3), "Inv depth wrong"
    print("âœ… Test 3: Inverse depth passed")

if __name__ == "__main__":
    test_helpers()
```

### 4.3. Phase 3: ResNetSAN01 í™•ì¥

**íŒŒì¼ ìˆ˜ì •**: `packnet_sfm/networks/depth/ResNetSAN01.py`

**ìˆ˜ì • ìœ„ì¹˜ 1: `__init__` ë©”ì„œë“œ**

```python
# packnet_sfm/networks/depth/ResNetSAN01.py

class ResNetSAN01(nn.Module):
    def __init__(self, dropout=None, version=None, use_film=False, film_scales=[0],
                 use_enhanced_lidar=False,
                 min_depth=0.5, max_depth=80.0,
                 use_dual_head=False,  # ğŸ†• ì¶”ê°€
                 **kwargs):
        super().__init__()
        
        # ì•ˆì „ ë³´ì • (ê¸°ì¡´ ì½”ë“œ)
        if max_depth <= 0: max_depth = 80.0
        if min_depth <= 0: min_depth = 0.5
        if max_depth <= min_depth: max_depth = min_depth + 1.0
        self.min_depth = float(min_depth)
        self.max_depth = float(max_depth)
        
        # ... (ê¸°ì¡´ encoder ì½”ë“œ ìƒëµ) ...
        
        # ResNet encoder (ê¸°ì¡´ ì½”ë“œ)
        self.encoder = ResnetEncoder(num_layers=num_layers, pretrained=True)
        
        # ========================================
        # ğŸ†• Decoder ì„ íƒ (Factory Pattern)
        # ========================================
        if use_dual_head:
            from packnet_sfm.networks.layers.resnet.dual_head_depth_decoder import DualHeadDepthDecoder
            self.decoder = DualHeadDepthDecoder(
                num_ch_enc=self.encoder.num_ch_enc,
                max_depth=self.max_depth,
                scales=range(4)
            )
            self.is_dual_head = True
            print(f"âœ… Using Dual-Head Decoder (max_depth={self.max_depth}m)")
        else:
            from packnet_sfm.networks.layers.resnet.depth_decoder import DepthDecoder
            self.decoder = DepthDecoder(num_ch_enc=self.encoder.num_ch_enc)
            self.is_dual_head = False
            print(f"âœ… Using Single-Head Decoder")
        
        # ... (ê¸°ì¡´ FiLM/Minkowski ì½”ë“œ ìœ ì§€) ...
        
        # ì„¤ì •
        self.use_film = use_film
        self.film_scales = film_scales
        self.use_enhanced_lidar = use_enhanced_lidar
        
        # ... (ë‚˜ë¨¸ì§€ ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...
```

**ìˆ˜ì • ìœ„ì¹˜ 2: `run_network` ë©”ì„œë“œ (ì¶œë ¥ í˜•ì‹ í†µì¼)**

```python
# packnet_sfm/networks/depth/ResNetSAN01.py

    def run_network(self, rgb, input_depth=None):
        """
        ğŸ†• Enhanced network execution with Dual-Head support
        """
        # Encode RGB features (ê¸°ì¡´ ì½”ë“œ)
        skip_features = self.encoder(rgb)
        
        # Enhanced sparse depth processing (ê¸°ì¡´ FiLM ì½”ë“œ ìœ ì§€)
        if input_depth is not None and self.use_film:
            # ... (ê¸°ì¡´ FiLM ì²˜ë¦¬ ì½”ë“œ ìœ ì§€) ...
            pass
        
        # Decode (Dual-Head ë˜ëŠ” Single-Head)
        outputs = self.decoder(skip_features)
        
        # ========================================
        # ğŸ†• ì¶œë ¥ í˜•ì‹ í†µì¼
        # ========================================
        if self.is_dual_head:
            # Dual-Head: {"integer": ..., "fractional": ...}
            # â†’ "disp" í‚¤ë¡œë„ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜
            from packnet_sfm.networks.layers.resnet.layers import dual_head_to_depth
            
            for scale in range(4):
                if ("integer", scale) in outputs:
                    # Depth ë³µì›
                    depth = dual_head_to_depth(
                        outputs[("integer", scale)],
                        outputs[("fractional", scale)],
                        self.max_depth
                    )
                    # Inverse depth ë³€í™˜ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜)
                    depth_clamped = torch.clamp(depth, min=self.min_depth, max=self.max_depth)
                    inv_depth = 1.0 / depth_clamped
                    
                    # ê¸°ì¡´ í‚¤ í˜•ì‹ìœ¼ë¡œë„ ì €ì¥ (í˜¸í™˜ì„±)
                    outputs[("disp", scale)] = inv_depth  # Actually inv_depth
                    outputs[("depth", scale)] = depth     # Actual depth
        else:
            # Single-Head: ê¸°ì¡´ ë™ì‘ ìœ ì§€
            pass
        
        if self.training:
            # í•™ìŠµ ì‹œ: ëª¨ë“  ìŠ¤ì¼€ì¼ ë°˜í™˜
            inv_depths = [outputs[("disp", i)] for i in range(4)]
            return inv_depths, skip_features
        else:
            # ì¶”ë¡  ì‹œ: scale 0ë§Œ ë°˜í™˜
            return outputs[("disp", 0)], None
```

**ë³€ê²½ ìš”ì•½**:
- `__init__`: +10ì¤„
- `run_network`: +20ì¤„
- **ì´ ë³€ê²½ëŸ‰**: ~30ì¤„
- **ê¸°ì¡´ ì½”ë“œ ìˆ˜ì •**: 0ì¤„

### 4.4. Phase 4: Loss Function êµ¬í˜„

**íŒŒì¼ ìƒì„±**: `packnet_sfm/losses/dual_head_depth_loss.py`

```python
# packnet_sfm/losses/dual_head_depth_loss.py
"""
Dual-Head Depth Loss for Integer-Fractional prediction

ì´ LossëŠ” ê¸°ì¡´ SupervisedLossì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ ì§€í•˜ë©´ì„œ,
Integer/Fractional í—¤ë“œë¥¼ ë³„ë„ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

from packnet_sfm.losses.loss_base import LossBase
from packnet_sfm.networks.layers.resnet.layers import decompose_depth, dual_head_to_depth


class DualHeadDepthLoss(LossBase):
    """
    Integer-Fractional Dual-Head Depth Loss
    
    ì´ LossëŠ” ì„¸ ê°€ì§€ ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:
    1. Integer Loss: ì •ìˆ˜ë¶€ ì˜ˆì¸¡ (L1 loss)
    2. Fractional Loss: ì†Œìˆ˜ë¶€ ì˜ˆì¸¡ (L1 loss, ë†’ì€ ê°€ì¤‘ì¹˜)
    3. Consistency Loss: ë³µì›ëœ ê¹Šì´ì˜ ì¼ê´€ì„± (L1 loss)
    
    Parameters
    ----------
    max_depth : float
        Maximum depth for integer normalization (default: 15.0)
    integer_weight : float
        Weight for integer loss (default: 1.0)
    fractional_weight : float
        Weight for fractional loss (default: 10.0) - ì •ë°€ë„ í•µì‹¬!
    consistency_weight : float
        Weight for consistency loss (default: 0.5)
    min_depth : float
        Minimum valid depth (default: 0.5)
    """
    
    def __init__(self, max_depth=15.0, 
                 integer_weight=1.0, 
                 fractional_weight=10.0,
                 consistency_weight=0.5,
                 min_depth=0.5,
                 **kwargs):
        super().__init__()
        
        self.max_depth = max_depth
        self.min_depth = min_depth
        self.integer_weight = integer_weight
        self.fractional_weight = fractional_weight
        self.consistency_weight = consistency_weight
        
        print(f"ğŸ¯ DualHeadDepthLoss initialized:")
        print(f"   Max depth: {max_depth}m")
        print(f"   Integer weight: {integer_weight}")
        print(f"   Fractional weight: {fractional_weight} (high precision!)")
        print(f"   Consistency weight: {consistency_weight}")
    
    def forward(self, outputs, depth_gt, return_logs=False, progress=0.0):
        """
        Compute dual-head depth loss
        
        Parameters
        ----------
        outputs : dict
            Model outputs containing:
            - ("integer", 0): [B, 1, H, W] sigmoid [0, 1]
            - ("fractional", 0): [B, 1, H, W] sigmoid [0, 1]
        depth_gt : torch.Tensor [B, 1, H, W]
            Ground truth depth
        return_logs : bool
            Whether to return detailed logs
        progress : float
            Training progress [0, 1] for dynamic weighting
        
        Returns
        -------
        loss_dict : dict
            {
                'loss': total_loss,
                'integer_loss': ...,
                'fractional_loss': ...,
                'consistency_loss': ...
            }
        """
        # Resize GT to match prediction size
        if depth_gt.shape[-2:] != outputs[("integer", 0)].shape[-2:]:
            depth_gt = F.interpolate(
                depth_gt, 
                size=outputs[("integer", 0)].shape[-2:],
                mode='nearest'
            )
        
        # Create valid mask
        mask = (depth_gt > self.min_depth) & (depth_gt < self.max_depth)
        
        if mask.sum() == 0:
            # No valid pixels
            return {
                'loss': torch.tensor(0.0, device=depth_gt.device, requires_grad=True),
                'integer_loss': torch.tensor(0.0),
                'fractional_loss': torch.tensor(0.0),
                'consistency_loss': torch.tensor(0.0)
            }
        
        # ========================================
        # 1. Decompose GT depth
        # ========================================
        integer_gt, fractional_gt = decompose_depth(depth_gt, self.max_depth)
        
        # ========================================
        # 2. Integer Loss (coarse prediction)
        # ========================================
        integer_pred = outputs[("integer", 0)]
        integer_loss = F.l1_loss(
            integer_pred[mask],
            integer_gt[mask],
            reduction='mean'
        )
        
        # ========================================
        # 3. Fractional Loss (fine prediction) - í•µì‹¬!
        # ========================================
        fractional_pred = outputs[("fractional", 0)]
        fractional_loss = F.l1_loss(
            fractional_pred[mask],
            fractional_gt[mask],
            reduction='mean'
        )
        
        # ========================================
        # 4. Consistency Loss (ì „ì²´ ê¹Šì´ ì¼ê´€ì„±)
        # ========================================
        depth_pred = dual_head_to_depth(integer_pred, fractional_pred, self.max_depth)
        consistency_loss = F.l1_loss(
            depth_pred[mask],
            depth_gt[mask],
            reduction='mean'
        )
        
        # ========================================
        # 5. Total Loss (ê°€ì¤‘ì¹˜ ì ìš©)
        # ========================================
        total_loss = (
            self.integer_weight * integer_loss +
            self.fractional_weight * fractional_loss +
            self.consistency_weight * consistency_loss
        )
        
        # Metrics for logging
        if return_logs:
            self.add_metric('integer_loss', integer_loss)
            self.add_metric('fractional_loss', fractional_loss)
            self.add_metric('consistency_loss', consistency_loss)
            self.add_metric('total_loss', total_loss)
            
            # Additional metrics
            with torch.no_grad():
                # Depth error
                depth_error = torch.abs(depth_pred[mask] - depth_gt[mask])
                self.add_metric('mean_depth_error', depth_error.mean())
                self.add_metric('median_depth_error', depth_error.median())
                
                # Integer accuracy (within 1 meter)
                integer_error = torch.abs(integer_pred[mask] * self.max_depth - integer_gt[mask] * self.max_depth)
                integer_acc = (integer_error < 1.0).float().mean()
                self.add_metric('integer_accuracy', integer_acc)
                
                # Fractional precision
                frac_error = torch.abs(fractional_pred[mask] - fractional_gt[mask])
                self.add_metric('fractional_rmse', torch.sqrt((frac_error ** 2).mean()))
        
        return {
            'loss': total_loss,
            'integer_loss': integer_loss.detach(),
            'fractional_loss': fractional_loss.detach(),
            'consistency_loss': consistency_loss.detach()
        }
```

### 4.5. Phase 5: Model Wrapper í†µí•©

**íŒŒì¼ ìˆ˜ì •**: `packnet_sfm/models/SemiSupCompletionModel.py`

**ìˆ˜ì • ìœ„ì¹˜: `supervised_loss` ë©”ì„œë“œ**

```python
# packnet_sfm/models/SemiSupCompletionModel.py

    def supervised_loss(self, inv_depths, gt_inv_depths,
                        return_logs=False, progress=0.0):
        """
        Calculates the supervised loss.
        
        ğŸ†• Dual-Head ëª¨ë¸ ìë™ ê°ì§€ ë° ì²˜ë¦¬
        """
        # ========================================
        # ğŸ†• Dual-Head ëª¨ë¸ ê°ì§€
        # ========================================
        if hasattr(self, 'depth_net') and hasattr(self.depth_net, 'is_dual_head') and self.depth_net.is_dual_head:
            # Dual-Head Loss ì‚¬ìš©
            from packnet_sfm.losses.dual_head_depth_loss import DualHeadDepthLoss
            
            # Dual-Head Loss ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
            if not hasattr(self, '_dual_head_loss'):
                self._dual_head_loss = DualHeadDepthLoss(
                    max_depth=self.max_depth,
                    min_depth=self.min_depth
                )
            
            # inv_depthsëŠ” ì‹¤ì œë¡œ outputs dictì„
            # gt_inv_depthsëŠ” ì‹¤ì œë¡œ depth_gtì„
            return self._dual_head_loss(
                outputs=inv_depths,  # {"integer": ..., "fractional": ...}
                depth_gt=gt_inv_depths,  # Actually depth
                return_logs=return_logs,
                progress=progress
            )
        else:
            # ê¸°ì¡´ Single-Head Loss ì‚¬ìš©
            return self._supervised_loss(
                inv_depths, gt_inv_depths,
                return_logs=return_logs, progress=progress
            )
```

**ë³€ê²½ëŸ‰**: +20ì¤„ (ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ìŒ)

---

## 5. YAML Configuration

### 5.1. Single-Head (ê¸°ì¡´ - Baseline)

```yaml
# configs/train_resnet_san_ncdb_640x384.yaml
model:
    name: 'SemiSupCompletionModel'
    depth_net:
        name: 'ResNetSAN01'
        version: '18A'
        use_dual_head: false  # Single-Head (ê¸°ì¡´)
        use_film: false
        use_enhanced_lidar: false
    params:
        min_depth: 0.5
        max_depth: 15.0
```

### 5.2. Dual-Head (ì‹ ê·œ - Experimental)

```yaml
# configs/train_resnet_san_ncdb_dual_head_640x384.yaml
model:
    name: 'SemiSupCompletionModel'
    loss:
        supervised_method: 'sparse-l1'  # Dual-Head loss ìë™ ì„ íƒë¨
        supervised_num_scales: 1
        supervised_loss_weight: 1.0
    depth_net:
        name: 'ResNetSAN01'
        version: '18A'
        use_dual_head: true   # ğŸ†• Dual-Head í™œì„±í™”
        use_film: false       # FiLM ë¹„í™œì„±í™” (ë‹¨ìˆœí™”)
        use_enhanced_lidar: false
    params:
        min_depth: 0.5
        max_depth: 15.0       # Integer head ë²”ìœ„
```

### 5.3. Dual-Head + FiLM (í•˜ì´ë¸Œë¦¬ë“œ)

```yaml
# configs/train_resnet_san_ncdb_dual_head_film_640x384.yaml
model:
    depth_net:
        name: 'ResNetSAN01'
        version: '18A'
        use_dual_head: true   # Dual-Head
        use_film: true        # + FiLM
        film_scales: [0]
        use_enhanced_lidar: false
    params:
        min_depth: 0.5
        max_depth: 15.0
```

---

## 6. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### 6.1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

**í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸**: `tests/test_dual_head_integration.py`

```bash
cd /workspace/packnet-sfm

# Test 1: Decoderë§Œ í…ŒìŠ¤íŠ¸
python -c "
from packnet_sfm.networks.layers.resnet.dual_head_depth_decoder import DualHeadDepthDecoder
import torch

decoder = DualHeadDepthDecoder([64, 64, 128, 256, 512], max_depth=15.0)
features = [torch.randn(1, c, 96//(2**i), 160//(2**i)) for i, c in enumerate([64, 64, 128, 256, 512])]
outputs = decoder(features)
assert ('integer', 0) in outputs and ('fractional', 0) in outputs
print('âœ… Decoder test passed')
"

# Test 2: Helper functions
python -c "
from packnet_sfm.networks.layers.resnet.layers import dual_head_to_depth, decompose_depth
import torch

depth = torch.tensor([[[[5.7]]]])
integer_gt, frac_gt = decompose_depth(depth, 15.0)
depth_recon = dual_head_to_depth(integer_gt, frac_gt, 15.0)
assert torch.allclose(depth, depth_recon)
print('âœ… Helper functions test passed')
"
```

### 6.2. í†µí•© í…ŒìŠ¤íŠ¸

**ì „ì²´ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸**:

```bash
# Single-Head (ê¸°ì¡´)
python -c "
from packnet_sfm.networks.depth.ResNetSAN01 import ResNetSAN01
import torch

model = ResNetSAN01(version='18A', use_dual_head=False, max_depth=15.0)
rgb = torch.randn(1, 3, 384, 640)
output = model.run_network(rgb)
print('âœ… Single-Head integration test passed')
"

# Dual-Head (ì‹ ê·œ)
python -c "
from packnet_sfm.networks.depth.ResNetSAN01 import ResNetSAN01
import torch

model = ResNetSAN01(version='18A', use_dual_head=True, max_depth=15.0)
rgb = torch.randn(1, 3, 384, 640)
outputs, _ = model.run_network(rgb)
assert all(('integer', i) in outputs or ('disp', i) in outputs for i in range(4))
print('âœ… Dual-Head integration test passed')
"
```

### 6.3. Backward Compatibility ê²€ì¦

```bash
# ê¸°ì¡´ checkpoint ë¡œë”© í…ŒìŠ¤íŠ¸
python scripts/eval.py \
    --checkpoint checkpoints/resnetsan01_640x384_linear_05_15/epoch_29.ckpt \
    --config configs/train_resnet_san_ncdb_640x384.yaml

# ì˜ˆìƒ ê²°ê³¼: ì •ìƒ ë¡œë”© ë° í‰ê°€ (use_dual_head=falseê°€ ê¸°ë³¸ê°’)
```

---

## 7. í•™ìŠµ ë° í‰ê°€

### 7.1. í•™ìŠµ ì‹¤í–‰

```bash
cd /workspace/packnet-sfm

# Dual-Head ëª¨ë¸ í•™ìŠµ
python scripts/train.py \
    configs/train_resnet_san_ncdb_dual_head_640x384.yaml

# í•™ìŠµ ì§„í–‰ í™•ì¸
tail -f checkpoints/resnetsan01_dual_head_640x384/training.log
```

### 7.2. í•™ìŠµ ëª¨ë‹ˆí„°ë§ (ì£¼ìš” ë©”íŠ¸ë¦­)

| Epoch | Integer Loss | Fractional Loss | Consistency Loss | Val abs_rel |
|-------|--------------|-----------------|------------------|-------------|
| 1 | 0.050 | 0.080 | 0.120 | ~0.150 |
| 5 | 0.010 | 0.040 | 0.060 | ~0.120 |
| 10 | 0.005 | 0.020 | 0.030 | ~0.090 |
| 20 | 0.002 | 0.010 | 0.015 | ~0.070 |
| **30** | **0.001** | **0.005** | **0.010** | **~0.055** |

**ê¸°ëŒ€ ì‚¬í•­**:
- Integer Loss: ë¹ ë¥´ê²Œ ìˆ˜ë ´ (Epoch 5ì— 0.01 ì´í•˜)
- Fractional Loss: ì²œì²œíˆ ê°ì†Œ (í•µì‹¬ ì •ë°€ë„)
- Consistency Loss: ì•ˆì •ì ìœ¼ë¡œ ê°ì†Œ

### 7.3. í‰ê°€

```bash
# FP32 í‰ê°€
python scripts/eval.py \
    --checkpoint checkpoints/resnetsan01_dual_head_640x384/epoch_30.ckpt \
    --config configs/train_resnet_san_ncdb_dual_head_640x384.yaml

# NPU INT8 ë³€í™˜ (ONNX)
python scripts/export_to_onnx.py \
    --checkpoint checkpoints/resnetsan01_dual_head_640x384/epoch_30.ckpt \
    --output onnx/resnetsan_dual_head.onnx \
    --dual_head  # ğŸ†• Dual output í”Œë˜ê·¸

# NPU í‰ê°€ (INT8)
python scripts/evaluate_npu_dual_head.py \
    --npu_dir outputs/dual_head_npu_results/
```

---

## 8. Troubleshooting

### 8.1. í•™ìŠµ ì¤‘ ë¬¸ì œ

**ë¬¸ì œ 1: Integer Lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ**
```
ì¦ìƒ: Integer lossê°€ 0.05 ì´ìƒì—ì„œ ë©ˆì¶¤
ì›ì¸: max_depth ì„¤ì • ì˜¤ë¥˜
í•´ê²°: YAMLì˜ max_depthê°€ ì‹¤ì œ ë°ì´í„° ë²”ìœ„ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
```

**ë¬¸ì œ 2: Fractional Lossê°€ ë„ˆë¬´ ë†’ìŒ**
```
ì¦ìƒ: Fractional loss > 0.05
ì›ì¸: Fractional weightê°€ ë„ˆë¬´ ë‚®ìŒ
í•´ê²°: fractional_weightë¥¼ 10.0 â†’ 15.0ìœ¼ë¡œ ì¦ê°€
```

**ë¬¸ì œ 3: NaN Loss**
```
ì¦ìƒ: Lossê°€ NaN
ì›ì¸: ì˜ëª»ëœ GT depth ê°’ (ë¬´í•œëŒ€ ë˜ëŠ” 0)
í•´ê²°: Datasetì—ì„œ valid mask í™•ì¸
```

### 8.2. ì½”ë“œ í†µí•© ë¬¸ì œ

**ë¬¸ì œ 1: ModuleNotFoundError**
```python
# ì¦ìƒ
ModuleNotFoundError: No module named 'packnet_sfm.networks.layers.resnet.dual_head_depth_decoder'

# ì›ì¸
íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê²½ë¡œ ì˜¤ë¥˜

# í•´ê²°
ls -la packnet_sfm/networks/layers/resnet/dual_head_depth_decoder.py
```

**ë¬¸ì œ 2: Key Error in outputs**
```python
# ì¦ìƒ
KeyError: ("integer", 0)

# ì›ì¸
ëª¨ë¸ì´ ì—¬ì „íˆ Single-Headë¡œ ë¡œë”©ë¨

# í•´ê²°
print(model.is_dual_head)  # Trueì—¬ì•¼ í•¨
YAMLì˜ use_dual_head: true í™•ì¸
```

### 8.3. NPU ë³€í™˜ ë¬¸ì œ

**ë¬¸ì œ 1: ONNX export ì‹¤íŒ¨**
```
ì¦ìƒ: Dual outputì´ ONNXì— ì—†ìŒ
í•´ê²°: export ìŠ¤í¬ë¦½íŠ¸ì— output_names ëª…ì‹œ
```

```python
# scripts/export_to_onnx.py ìˆ˜ì •
torch.onnx.export(
    model,
    dummy_input,
    output_path,
    input_names=['rgb'],
    output_names=['integer_sigmoid', 'fractional_sigmoid'],  # ğŸ†• ëª…ì‹œ
    dynamic_axes={'rgb': {0: 'batch_size'}}
)
```

---

## 9. ì˜ˆìƒ ê²°ê³¼

### 9.1. FP32 ì„±ëŠ¥ (PyTorch)

| Metric | Single-Head (Baseline) | Dual-Head (Expected) | Improvement |
|--------|------------------------|----------------------|-------------|
| abs_rel | 0.0434 | **0.038~0.042** | 10-15% |
| rmse | 0.391m | **0.35~0.38m** | 10-15% |
| Î´<1.25 | 0.9759 | **0.980~0.985** | +0.5% |

### 9.2. INT8 ì„±ëŠ¥ (NPU)

| Metric | Phase 1 (300 cal) | Dual-Head INT8 | Improvement |
|--------|-------------------|----------------|-------------|
| abs_rel | 0.1139 | **0.055~0.065** | **47-52%** |
| rmse | 0.751m | **0.45~0.55m** | **33-40%** |
| Î´<1.25 | 0.9061 | **0.965~0.975** | **6-7%** |

**ëª©í‘œ ë‹¬ì„±**:
- âœ… abs_rel < 0.09: **ê³ í™•ë¥  ë‹¬ì„±**
- âœ… ì–‘ìí™” ì˜¤ì°¨: Â±28mm â†’ **Â±2mm** (14ë°° ê°œì„ )

---

## 10. ìš”ì•½

### 10.1. í•µì‹¬ ì„¤ê³„ ì›ì¹™

1. âœ… **Backward Compatibility**: ê¸°ì¡´ ì½”ë“œ 100% ìœ ì§€
2. âœ… **Parameter-driven**: YAMLë§Œìœ¼ë¡œ Single/Dual ì „í™˜
3. âœ… **Minimal Changes**: ì´ ~60ì¤„ ì¶”ê°€ (0ì¤„ ìˆ˜ì •)
4. âœ… **Independent Testing**: ê° ì»´í¬ë„ŒíŠ¸ ë…ë¦½ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

### 10.2. íŒŒì¼ ë³€ê²½ ìš”ì•½

| íŒŒì¼ | ë³€ê²½ ìœ í˜• | ì¤„ ìˆ˜ |
|------|-----------|-------|
| `dual_head_depth_decoder.py` | ğŸ†• ì‹ ê·œ | ~150ì¤„ |
| `layers.py` | â• í•¨ìˆ˜ ì¶”ê°€ | +40ì¤„ |
| `ResNetSAN01.py` | â• ë¡œì§ ì¶”ê°€ | +30ì¤„ |
| `dual_head_depth_loss.py` | ğŸ†• ì‹ ê·œ | ~120ì¤„ |
| `SemiSupCompletionModel.py` | â• ë¶„ê¸° ì¶”ê°€ | +20ì¤„ |
| **Total** | - | **~360ì¤„** |

### 10.3. ë‹¤ìŒ ë‹¨ê³„

**Week 1** (Day 1-5):
- [ ] Day 1: `DualHeadDepthDecoder` êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸
- [ ] Day 2: Helper functions ë° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- [ ] Day 3: `ResNetSAN01` í†µí•© ë° í†µí•© í…ŒìŠ¤íŠ¸
- [ ] Day 4: Loss function êµ¬í˜„ ë° ê²€ì¦
- [ ] Day 5: YAML config ì¤€ë¹„ ë° í•™ìŠµ ì‹œì‘

**Week 2-3** (í•™ìŠµ ë° í‰ê°€):
- [ ] Week 2: ëª¨ë¸ í•™ìŠµ (30 epochs)
- [ ] Week 3: FP32 í‰ê°€, NPU ë³€í™˜, INT8 í‰ê°€

**Success Criteria**:
- âœ… ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- âœ… Backward compatibility ê²€ì¦
- âœ… FP32 abs_rel < 0.045
- âœ… **INT8 abs_rel < 0.065** (ëª©í‘œ)

### 6.1. ì˜ˆìƒ ì„±ëŠ¥

**FP32 (PyTorch)**:

| Metric | í˜„ì¬ Single-Head | ì˜ˆìƒ Dual-Head | ê°œì„ ìœ¨ |
|--------|------------------|----------------|--------|
| abs_rel | 0.0434 | **0.038~0.042** | **10-15%** |
| rmse | 0.391m | **0.35~0.38m** | **10-15%** |

> Dual-HeadëŠ” FP32ì—ì„œë„ ì•½ê°„ì˜ ì„±ëŠ¥ í–¥ìƒ ì˜ˆìƒ (ë” ëª…ì‹œì ì¸ í‘œí˜„)

**INT8 (NPU)**:

| Metric | Phase 1 (300 cal) | ì˜ˆìƒ Dual-Head | ê°œì„ ìœ¨ |
|--------|-------------------|----------------|--------|
| abs_rel | 0.1139 | **0.055~0.060** | **51-47%** |
| rmse | 0.751m | **0.45~0.50m** | **40-33%** |
| Î´<1.25 | 0.9061 | **0.970~0.975** | **7%** |

**ëª©í‘œ ë‹¬ì„± ì—¬ë¶€**:
- âœ… **abs_rel < 0.09**: ë†’ì€ í™•ë¥ ë¡œ ë‹¬ì„± (0.055~0.060 ì˜ˆìƒ)
- âœ… **ì–‘ìí™” ì˜¤ì°¨ ê°ì†Œ**: Â±28mm â†’ Â±2mm (14ë°° ê°œì„ )
- âœ… **FP32 ëŒ€ë¹„ ê²©ì°¨ ì¶•ì†Œ**: 2.6ë°° â†’ 1.5ë°°

---

**ì´ ë¬¸ì„œëŠ” ì½”ë“œë² ì´ìŠ¤ë¥¼ ê¹Šì´ ë¶„ì„í•œ í›„ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ê¸°ì¡´ ê¸°ëŠ¥ì„ í•´ì¹˜ì§€ ì•Šê³  ì•ˆì „í•˜ê²Œ Dual-Headë¥¼ í†µí•©í•˜ëŠ” ì‹¤ë¬´ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.**
