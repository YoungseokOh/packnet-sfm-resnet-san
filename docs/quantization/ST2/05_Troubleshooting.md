# 5. Troubleshooting

## í•™ìŠµ ì¤‘ ë¬¸ì œ

### ë¬¸ì œ 1: Integer Lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ

**ì¦ìƒ**:
```
Epoch 10: integer_loss=0.05, fractional_loss=0.02, consistency_loss=0.03
Epoch 20: integer_loss=0.05, fractional_loss=0.01, consistency_loss=0.015
```
Integer lossê°€ 0.05 ì´ìƒì—ì„œ ë©ˆì¶¤

**ì›ì¸**:
- `max_depth` ì„¤ì •ì´ ì‹¤ì œ ë°ì´í„° ë²”ìœ„ì™€ ë¶ˆì¼ì¹˜
- Integer headê°€ ìž˜ëª»ëœ ë²”ìœ„ë¡œ ì •ê·œí™”ë¨

**í•´ê²° ë°©ë²•**:

```bash
# 1. ë°ì´í„°ì…‹ì˜ ì‹¤ì œ depth ë²”ìœ„ í™•ì¸
python -c "
import numpy as np
from packnet_sfm.datasets.ncdb_dataset import NCDBDataset

dataset = NCDBDataset(...)
depths = [sample['depth'].numpy() for sample in dataset[:100]]
print(f'Min depth: {np.min(depths):.2f}m')
print(f'Max depth: {np.max(depths):.2f}m')
print(f'Mean depth: {np.mean(depths):.2f}m')
"

# 2. YAMLì˜ max_depth ìˆ˜ì •
# configs/train_resnet_san_ncdb_dual_head_640x384.yaml
params:
    max_depth: 15.0  # ì‹¤ì œ ë°ì´í„° ë²”ìœ„ì— ë§žì¶° ì¡°ì •
```

**ê²€ì¦**:
```python
# Integer GT ë¶„í¬ í™•ì¸
from packnet_sfm.networks.layers.resnet.layers import decompose_depth
import torch

depth_samples = torch.randn(100, 1, 384, 640) * 10  # ì˜ˆì‹œ
integer_gt, frac_gt = decompose_depth(depth_samples, max_depth=15.0)

print(f"Integer GT range: [{integer_gt.min():.3f}, {integer_gt.max():.3f}]")
# ì˜ˆìƒ: [0.0, 1.0] ë²”ìœ„ì— ê· ë“± ë¶„í¬
```

---

### ë¬¸ì œ 2: Fractional Lossê°€ ë„ˆë¬´ ë†’ìŒ

**ì¦ìƒ**:
```
Epoch 30: fractional_loss=0.08 (ë„ˆë¬´ ë†’ìŒ, ëª©í‘œ: 0.005)
```

**ì›ì¸**:
1. Fractional weightê°€ ë„ˆë¬´ ë‚®ìŒ (ëª¨ë¸ì´ ì†Œìˆ˜ë¶€ë¥¼ ë¬´ì‹œ)
2. Learning rateê°€ ë„ˆë¬´ ë†’ìŒ (overshooting)

**í•´ê²° ë°©ë²• 1: Weight ì¡°ì •**

```python
# packnet_sfm/losses/dual_head_depth_loss.py
class DualHeadDepthLoss(LossBase):
    def __init__(self, ..., fractional_weight=10.0, ...):
        # ê¸°ì¡´: 10.0
        # ì‹œë„: 15.0 ë˜ëŠ” 20.0ìœ¼ë¡œ ì¦ê°€
        self.fractional_weight = fractional_weight
```

**í•´ê²° ë°©ë²• 2: Learning Rate ê°ì†Œ**

```yaml
# configs/train_resnet_san_ncdb_dual_head_640x384.yaml
optimizer:
    learning_rate: 1.0e-4  # ê¸°ì¡´: 2.0e-4ì—ì„œ ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ
```

**ê²€ì¦**:
```bash
# Loss ë¹„ìœ¨ í™•ì¸
python -c "
# Training logì—ì„œ loss ë¹„ìœ¨ í™•ì¸
# ì´ìƒì ì¸ ë¹„ìœ¨: integer:fractional:consistency = 1:10:5
# ì‹¤ì œê°€ 1:2:5ë¼ë©´ fractional weight ì¦ê°€ í•„ìš”
"
```

---

### ë¬¸ì œ 3: NaN Loss

**ì¦ìƒ**:
```
Epoch 5: loss=NaN, integer_loss=NaN
RuntimeError: Found NaN in loss
```

**ì›ì¸**:
1. Ground truth depthì— ë¬´í•œëŒ€ ë˜ëŠ” 0 ê°’ í¬í•¨
2. Division by zero in inverse depth conversion
3. Gradient explosion

**í•´ê²° ë°©ë²• 1: GT ë°ì´í„° ê²€ì¦**

```python
# packnet_sfm/datasets/ncdb_dataset.py
def __getitem__(self, idx):
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    # ðŸ†• Depth ìœ íš¨ì„± ê²€ì‚¬
    depth = sample['depth']
    
    # ë¬´í•œëŒ€ ì œê±°
    depth = torch.where(torch.isinf(depth), torch.zeros_like(depth), depth)
    
    # ìœ íš¨ ë²”ìœ„ í´ë¦¬í•‘
    depth = torch.clamp(depth, min=0.5, max=15.0)
    
    # NaN ì œê±°
    depth = torch.where(torch.isnan(depth), torch.zeros_like(depth), depth)
    
    sample['depth'] = depth
    return sample
```

**í•´ê²° ë°©ë²• 2: Loss í•¨ìˆ˜ì— ì•ˆì „ìž¥ì¹˜ ì¶”ê°€**

```python
# packnet_sfm/losses/dual_head_depth_loss.py
def forward(self, outputs, depth_gt, ...):
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    # ðŸ†• NaN ì²´í¬
    if torch.isnan(depth_gt).any() or torch.isinf(depth_gt).any():
        print("âš ï¸ Warning: NaN or Inf in GT depth, skipping batch")
        return {
            'loss': torch.tensor(0.0, device=depth_gt.device, requires_grad=True),
            'integer_loss': torch.tensor(0.0),
            'fractional_loss': torch.tensor(0.0),
            'consistency_loss': torch.tensor(0.0)
        }
    
    # Valid mask ê°•í™”
    mask = (depth_gt > self.min_depth) & (depth_gt < self.max_depth)
    mask = mask & (~torch.isnan(depth_gt)) & (~torch.isinf(depth_gt))
    
    if mask.sum() == 0:
        # No valid pixels
        return {...}
    
    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ...
```

**í•´ê²° ë°©ë²• 3: Gradient Clipping**

```yaml
# configs/train_resnet_san_ncdb_dual_head_640x384.yaml
trainer:
    gradient_clip_val: 1.0  # ðŸ†• Gradient norm ì œí•œ
    gradient_clip_algorithm: 'norm'
```

---

### ë¬¸ì œ 4: í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼

**ì¦ìƒ**:
- Single-Head: 5 min/epoch
- Dual-Head: 12 min/epoch (2.4ë°° ëŠë¦¼)

**ì›ì¸**:
- Dual-HeadëŠ” 2ë°°ì˜ ì¶œë ¥ í—¤ë“œë¥¼ ê³„ì‚°
- ì¶”ê°€ loss ê³„ì‚° (integer + fractional + consistency)

**í•´ê²° ë°©ë²• 1: Batch Size ì¦ê°€ (GPU ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ)**

```yaml
datasets:
    train:
        batch_size: 8  # ê¸°ì¡´: 4ì—ì„œ 2ë°° ì¦ê°€
```

**í•´ê²° ë°©ë²• 2: Multi-Scale Loss ë¹„í™œì„±í™”**

```yaml
model:
    loss:
        supervised_num_scales: 1  # ê¸°ì¡´: 4ì—ì„œ 1ë¡œ ê°ì†Œ (scale 0ë§Œ ì‚¬ìš©)
```

**í•´ê²° ë°©ë²• 3: Mixed Precision Training**

```yaml
trainer:
    precision: 16  # ðŸ†• FP16 í˜¼í•© ì •ë°€ë„ í•™ìŠµ
```

---

## ì½”ë“œ í†µí•© ë¬¸ì œ

### ë¬¸ì œ 5: ModuleNotFoundError

**ì¦ìƒ**:
```python
ModuleNotFoundError: No module named 'packnet_sfm.networks.layers.resnet.dual_head_depth_decoder'
```

**ì›ì¸**:
- íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê²½ë¡œ ì˜¤ë¥˜

**í•´ê²° ë°©ë²•**:

```bash
# 1. íŒŒì¼ ì¡´ìž¬ í™•ì¸
ls -la packnet_sfm/networks/layers/resnet/dual_head_depth_decoder.py

# 2. __init__.py í™•ì¸
cat packnet_sfm/networks/layers/resnet/__init__.py

# 3. __init__.pyê°€ ì—†ìœ¼ë©´ ìƒì„±
touch packnet_sfm/networks/layers/resnet/__init__.py

# 4. Python path í™•ì¸
python -c "import sys; print('\n'.join(sys.path))"

# 5. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•˜ëŠ”ì§€ í™•ì¸
pwd  # /workspace/packnet-sfmì´ì–´ì•¼ í•¨
```

---

### ë¬¸ì œ 6: KeyError in outputs

**ì¦ìƒ**:
```python
KeyError: ("integer", 0)
```

**ì›ì¸**:
- ëª¨ë¸ì´ ì—¬ì „ížˆ Single-Headë¡œ ë¡œë”©ë¨
- YAMLì˜ `use_dual_head` íŒŒë¼ë¯¸í„°ê°€ ì „ë‹¬ë˜ì§€ ì•ŠìŒ

**í•´ê²° ë°©ë²•**:

```bash
# 1. ëª¨ë¸ ì´ˆê¸°í™” í™•ì¸
python -c "
from packnet_sfm.networks.depth.ResNetSAN01 import ResNetSAN01

model = ResNetSAN01(version='18A', use_dual_head=True, max_depth=15.0)
print(f'is_dual_head: {model.is_dual_head}')  # Trueì—¬ì•¼ í•¨
print(f'Decoder type: {type(model.decoder).__name__}')  # DualHeadDepthDecoderì—¬ì•¼ í•¨
"

# 2. YAML config í™•ì¸
cat configs/train_resnet_san_ncdb_dual_head_640x384.yaml | grep use_dual_head
# ì¶œë ¥: use_dual_head: true

# 3. Config ë¡œë”© í™•ì¸
python -c "
from packnet_sfm.utils.config import parse_train_file

config = parse_train_file('configs/train_resnet_san_ncdb_dual_head_640x384.yaml')
print(config['model']['depth_net'])
"
```

**ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€**:

```python
# packnet_sfm/networks/depth/ResNetSAN01.py
def __init__(self, ..., use_dual_head=False, **kwargs):
    print(f"ðŸ” ResNetSAN01 init: use_dual_head={use_dual_head}")  # ðŸ†• ë””ë²„ê¹…
    
    if use_dual_head:
        print("âœ… Creating DualHeadDepthDecoder")  # ðŸ†•
        self.decoder = DualHeadDepthDecoder(...)
        self.is_dual_head = True
    else:
        print("âœ… Creating standard DepthDecoder")  # ðŸ†•
        self.decoder = DepthDecoder(...)
        self.is_dual_head = False
```

---

### ë¬¸ì œ 7: Checkpoint ë¡œë”© ì‹¤íŒ¨

**ì¦ìƒ**:
```python
RuntimeError: Error(s) in loading state_dict:
    size mismatch for decoder.convs.("integer_conv", 0).conv.weight
```

**ì›ì¸**:
- Single-Head checkpointë¥¼ Dual-Head ëª¨ë¸ì— ë¡œë”©í•˜ë ¤ í•¨
- ë˜ëŠ” ê·¸ ë°˜ëŒ€

**í•´ê²° ë°©ë²• 1: Strict Loading ë¹„í™œì„±í™”**

```python
# scripts/train.py ë˜ëŠ” eval.py
checkpoint = torch.load(args.checkpoint)
model.load_state_dict(checkpoint['state_dict'], strict=False)  # ðŸ†• strict=False
```

**í•´ê²° ë°©ë²• 2: Checkpoint ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸**

```python
# scripts/convert_checkpoint.py
import torch

# Single-Head â†’ Dual-Head ë³€í™˜
checkpoint = torch.load('single_head.ckpt')
state_dict = checkpoint['state_dict']

# Decoder weightsë§Œ ì œê±° (ë‚˜ë¨¸ì§€ëŠ” ìž¬ì‚¬ìš©)
new_state_dict = {k: v for k, v in state_dict.items() if 'decoder' not in k}

# ìƒˆ checkpoint ì €ìž¥
torch.save({'state_dict': new_state_dict}, 'dual_head_init.ckpt')
```

**í•´ê²° ë°©ë²• 3: From Scratch í•™ìŠµ**

```yaml
# configs/train_resnet_san_ncdb_dual_head_640x384.yaml
checkpoint:
    resume: null  # Checkpoint ì—†ì´ ì²˜ìŒë¶€í„° í•™ìŠµ
```

---

## NPU ë³€í™˜ ë¬¸ì œ

### ë¬¸ì œ 8: ONNX Export ì‹¤íŒ¨

**ì¦ìƒ**:
```python
RuntimeError: ONNX export failed: Dual output is not exported
```

**ì›ì¸**:
- PyTorch â†’ ONNX ë³€í™˜ ì‹œ output_names ëª…ì‹œ í•„ìš”

**í•´ê²° ë°©ë²•**:

```python
# scripts/export_to_onnx.py ìˆ˜ì •
import torch
from packnet_sfm.networks.depth.ResNetSAN01 import ResNetSAN01

# ëª¨ë¸ ë¡œë”©
model = ResNetSAN01(version='18A', use_dual_head=True, max_depth=15.0)
checkpoint = torch.load(args.checkpoint)
model.load_state_dict(checkpoint['state_dict'], strict=False)
model.eval()

# Wrapper í´ëž˜ìŠ¤ë¡œ ì¶œë ¥ í˜•ì‹ ëª…ì‹œ
class DualHeadWrapper(torch.nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model
    
    def forward(self, rgb):
        self.model.eval()
        outputs = self.model.decoder(self.model.encoder(rgb))
        
        # ëª…ì‹œì ìœ¼ë¡œ ë‘ ì¶œë ¥ ë°˜í™˜
        integer_sigmoid = outputs[("integer", 0)]
        fractional_sigmoid = outputs[("fractional", 0)]
        
        return integer_sigmoid, fractional_sigmoid

# Wrapperë¡œ export
wrapper = DualHeadWrapper(model)
dummy_input = torch.randn(1, 3, 384, 640)

torch.onnx.export(
    wrapper,
    dummy_input,
    args.output,
    input_names=['rgb'],
    output_names=['integer_sigmoid', 'fractional_sigmoid'],  # ðŸ†• ëª…ì‹œ
    dynamic_axes={
        'rgb': {0: 'batch_size'},
        'integer_sigmoid': {0: 'batch_size'},
        'fractional_sigmoid': {0: 'batch_size'}
    },
    opset_version=11,
    do_constant_folding=True,
    verbose=True
)

print(f"âœ… ONNX export complete: {args.output}")
```

---

### ë¬¸ì œ 9: NPU ì–‘ìží™” ì˜¤ë¥˜

**ì¦ìƒ**:
```
Pulsar2 error: Calibration failed for dual outputs
```

**ì›ì¸**:
- NPUê°€ ë‘ ì¶œë ¥ì„ ë…ë¦½ì ìœ¼ë¡œ calibration í•„ìš”

**í•´ê²° ë°©ë²•**:

```json
// configs/npu_config_dual_head.json
{
  "model_type": "ONNX",
  "npu_mode": "NPU3",
  "quant": {
    "input_configs": [
      {
        "tensor_name": "rgb",
        "calibration_dataset": "calibration_data_300/",
        "calibration_size": 300,
        "calibration_mean": [0.485, 0.456, 0.406],
        "calibration_std": [0.229, 0.224, 0.225]
      }
    ],
    "output_configs": [
      {
        "tensor_name": "integer_sigmoid",
        "calibration_method": "MinMax",
        "quantize_method": "PerTensor"
      },
      {
        "tensor_name": "fractional_sigmoid",
        "calibration_method": "MinMax",
        "quantize_method": "PerTensor"
      }
    ],
    "calibration_method": "MinMax",
    "precision_analysis": true
  }
}
```

---

### ë¬¸ì œ 10: NPU í‰ê°€ ê²°ê³¼ ì´ìƒ

**ì¦ìƒ**:
```
NPU INT8: abs_rel=0.15 (ì˜ˆìƒ: 0.055ë³´ë‹¤ í›¨ì”¬ ë†’ìŒ)
```

**ì›ì¸**:
1. Depth ë³µì› ë¡œì§ ì˜¤ë¥˜
2. Integer/Fractional ì¶œë ¥ ìˆœì„œ ë°”ë€œ
3. max_depth ê°’ ë¶ˆì¼ì¹˜

**í•´ê²° ë°©ë²• 1: ì¶œë ¥ ê²€ì¦**

```python
# scripts/evaluate_npu_dual_head.py
import onnxruntime as ort
import numpy as np

session = ort.InferenceSession(args.npu_model)

# ì¶œë ¥ ì´ë¦„ í™•ì¸
output_names = [output.name for output in session.get_outputs()]
print(f"NPU output names: {output_names}")
# ì˜ˆìƒ: ['integer_sigmoid', 'fractional_sigmoid']

# ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
rgb_test = np.random.randn(1, 3, 384, 640).astype(np.float32)
outputs = session.run(None, {'rgb': rgb_test})

print(f"Output 0 shape: {outputs[0].shape}, range: [{outputs[0].min():.3f}, {outputs[0].max():.3f}]")
print(f"Output 1 shape: {outputs[1].shape}, range: [{outputs[1].min():.3f}, {outputs[1].max():.3f}]")

# Sigmoid ë²”ìœ„ [0, 1] í™•ì¸
assert 0.0 <= outputs[0].min() and outputs[0].max() <= 1.0, "Integer sigmoid out of range"
assert 0.0 <= outputs[1].min() and outputs[1].max() <= 1.0, "Fractional sigmoid out of range"
```

**í•´ê²° ë°©ë²• 2: Depth ë³µì› ê²€ì¦**

```python
# scripts/evaluate_npu_dual_head.py
from packnet_sfm.networks.layers.resnet.layers import dual_head_to_depth
import torch

# NPU ì¶œë ¥
integer_sigmoid = torch.from_numpy(outputs[0])
fractional_sigmoid = torch.from_numpy(outputs[1])

# Depth ë³µì›
depth_pred = dual_head_to_depth(integer_sigmoid, fractional_sigmoid, max_depth=15.0)

print(f"Predicted depth range: [{depth_pred.min():.2f}, {depth_pred.max():.2f}]m")
# ì˜ˆìƒ: [0.0, 16.0]m (max_depth + 1)

# GTì™€ ë¹„êµ
print(f"GT depth range: [{depth_gt.min():.2f}, {depth_gt.max():.2f}]m")

# Sanity check
assert depth_pred.min() >= 0.0, "Negative depth"
assert depth_pred.max() <= 16.0, "Depth exceeds max_depth + 1"
```

---

## ì¼ë°˜ì ì¸ ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•™ìŠµ ì‹œìž‘ ì „

- [ ] ëª¨ë“  íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìƒì„±ë¨
- [ ] `use_dual_head=True` í™•ì¸ (YAML, ëª¨ë¸ ì´ˆê¸°í™”)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] Dummy dataë¡œ 1 step forward/backward ì„±ê³µ

### í•™ìŠµ ì¤‘

- [ ] Loss ê°’ì´ NaNì´ ì•„ë‹˜
- [ ] Lossê°€ ê°ì†Œ ì¶”ì„¸
- [ ] Gradient normì´ í­ë°œí•˜ì§€ ì•ŠìŒ (< 10.0)
- [ ] Validation metrics ê°œì„ 
- [ ] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ (< 11GB for V100)

### í•™ìŠµ í›„

- [ ] FP32 abs_rel < 0.045
- [ ] Checkpoint ì €ìž¥ ì •ìƒ
- [ ] ONNX export ì„±ê³µ
- [ ] NPU ë³€í™˜ ì„±ê³µ
- [ ] NPU INT8 abs_rel < 0.065

### NPU ë³€í™˜ í›„

- [ ] ONNX ì¶œë ¥ ê°œìˆ˜ = 2
- [ ] ì¶œë ¥ ì´ë¦„ í™•ì¸ (integer_sigmoid, fractional_sigmoid)
- [ ] ì¶œë ¥ ê°’ ë²”ìœ„ [0, 1]
- [ ] Depth ë³µì› ë¡œì§ ì •ìƒ
- [ ] max_depth ê°’ ì¼ì¹˜ (PyTorch vs NPU)

---

## ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ë¡œê·¸ ë¶„ì„ ë„êµ¬

```bash
# Loss ì¶”ì´ ê·¸ëž˜í”„
python scripts/plot_training_logs.py \
    --log checkpoints/resnetsan01_dual_head_640x384/training.log

# Tensorboard
tensorboard --logdir checkpoints/resnetsan01_dual_head_640x384

# Metric ë¹„êµ
python scripts/compare_metrics.py \
    --baseline outputs/single_head_fp32_results/metrics.json \
    --experiment outputs/dual_head_fp32_results/metrics.json
```

### ë¬¸ì˜ ì±„ë„

- ì½”ë“œë² ì´ìŠ¤ ì´ìŠˆ: GitHub Issues
- í•™ìŠµ ë¬¸ì œ: Training logs ì²¨ë¶€
- NPU ë³€í™˜ ë¬¸ì œ: ONNX íŒŒì¼ ë° config ì²¨ë¶€

---

**ì´ Troubleshooting ê°€ì´ë“œëŠ” ì‹¤ì œ êµ¬í˜„ ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìžˆëŠ” ëŒ€ë¶€ë¶„ì˜ ë¬¸ì œë¥¼ ë‹¤ë£¨ê³  ìžˆìŠµë‹ˆë‹¤. ê° ë¬¸ì œì— ëŒ€í•œ êµ¬ì²´ì ì¸ í•´ê²° ë°©ë²•ê³¼ ê²€ì¦ ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìžˆì–´ ë¹ ë¥¸ ë””ë²„ê¹…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.**
