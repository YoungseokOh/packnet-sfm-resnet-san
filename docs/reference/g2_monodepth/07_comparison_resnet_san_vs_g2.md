# ResNet-SAN vs G2-MonoDepth ë¹„êµ ë¶„ì„

## 1. ë°ì´í„° ì²˜ë¦¬ ë¹„êµ

### 1.1 í˜„ì¬ ResNet-SAN ë°ì´í„° íŒŒì´í”„ë¼ì¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ResNet-SAN Data Pipeline                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“¥ Input                                                       â”‚
â”‚  â””â”€â”€ RGB ì´ë¯¸ì§€ (3 channels)                                    â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”„ Augmentation (transforms.py)                                â”‚
â”‚  â”œâ”€â”€ crop_sample()          : ì´ë¯¸ì§€ crop                       â”‚
â”‚  â”œâ”€â”€ resize_sample()        : ë¦¬ì‚¬ì´ì¦ˆ                          â”‚
â”‚  â”œâ”€â”€ duplicate_sample()     : original ë³µì‚¬                     â”‚
â”‚  â”œâ”€â”€ colorjitter_sample()   : brightness, contrast, saturation, hue â”‚
â”‚  â””â”€â”€ to_tensor_sample()     : í…ì„œ ë³€í™˜                         â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“¤ Output                                                      â”‚
â”‚  â””â”€â”€ sample['rgb'], sample['depth'], sample['intrinsics']       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 G2-MonoDepth ë°ì´í„° íŒŒì´í”„ë¼ì¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  G2-MonoDepth Data Pipeline                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“¥ Input                                                       â”‚
â”‚  â””â”€â”€ RGB + Sparse Depth + Hole Mask (5 channels)                â”‚
â”‚                                                                 â”‚
â”‚  ğŸ”„ Augmentation (data_tools.py)                                â”‚
â”‚  â”œâ”€â”€ horizontal_flip()      : ì¢Œìš° ë°˜ì „ (50%)                   â”‚
â”‚  â”œâ”€â”€ color_jitter()         : brightness, contrast, sat, hue    â”‚
â”‚  â”œâ”€â”€ random_sparsity()      : 0~100% sparsity ì ìš© â­            â”‚
â”‚  â”œâ”€â”€ point_hole()           : depthì— êµ¬ë© ìƒì„± (50%) â­         â”‚
â”‚  â”œâ”€â”€ point_noise()          : depthì— ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ (50%) â­   â”‚
â”‚  â””â”€â”€ point_blur()           : depthì— ë¸”ëŸ¬ ì ìš© (50%) â­         â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“¤ Output                                                      â”‚
â”‚  â””â”€â”€ rgb, depth_gt, point, hole_point                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Augmentation ë¹„êµí‘œ

| Augmentation | ResNet-SAN | G2-MonoDepth | ë¹„ê³  |
|--------------|------------|--------------|------|
| **ê¸°ë³¸** |
| Horizontal Flip | âŒ ì—†ìŒ | âœ… 50% | ì¢Œìš° ëŒ€ì¹­ |
| Vertical Flip | âŒ | âŒ | ë‘˜ ë‹¤ ë¯¸ì‚¬ìš© |
| Rotation | âŒ | âŒ | ë‘˜ ë‹¤ ë¯¸ì‚¬ìš© |
| **Color** |
| Brightness | âœ… | âœ… | ìœ ì‚¬ |
| Contrast | âœ… | âœ… | ìœ ì‚¬ |
| Saturation | âœ… | âœ… | ìœ ì‚¬ |
| Hue | âœ… | âœ… | ìœ ì‚¬ |
| Color Matrix | âœ… | âŒ | ResNet-SANë§Œ |
| **Spatial** |
| Crop | âœ… | âŒ | ResNet-SANë§Œ |
| Resize | âœ… | âŒ (ê³ ì • í¬ê¸°) | |
| **Depth ê´€ë ¨** |
| Random Sparsity | âŒ | âœ… 0~100% | G2ë§Œ (RGB+Xìš©) |
| Point Hole | âŒ | âœ… 50% | G2ë§Œ |
| Point Noise | âŒ | âœ… 50% | G2ë§Œ |
| Point Blur | âŒ | âœ… 50% | G2ë§Œ |
| **Advanced** |
| RandAugment | âš ï¸ êµ¬í˜„ë¨ (ë¯¸ì‚¬ìš©) | âŒ | |
| Random Erasing | âš ï¸ êµ¬í˜„ë¨ (ë¯¸ì‚¬ìš©) | âŒ | |
| MixUp | âš ï¸ êµ¬í˜„ë¨ (ë¯¸ì‚¬ìš©) | âŒ | |
| CutMix | âš ï¸ êµ¬í˜„ë¨ (ë¯¸ì‚¬ìš©) | âŒ | |

### 1.4 ResNet-SAN ë°ì´í„° ì²˜ë¦¬ì˜ ë¶€ì¡±í•œ ì 

#### âŒ 1. Horizontal Flip ë¯¸ì ìš©
```python
# í˜„ì¬: colorjitterë§Œ ì ìš©
def train_transforms(sample, image_shape, jittering, crop_train_borders):
    ...
    if len(jittering) > 0:
        sample = colorjitter_sample(sample, jittering)  # Colorë§Œ!
    ...
```

**ë¬¸ì œì **: 
- ë°ì´í„° ë‹¤ì–‘ì„± ë¶€ì¡±
- ì¢Œìš° ëŒ€ì¹­ í•™ìŠµ ê¸°íšŒ ì†ì‹¤

**ì œì•ˆ**: Horizontal flip (50% í™•ë¥ ) ì¶”ê°€

#### âŒ 2. Depth Augmentation ì „ë¬´
```
G2-MonoDepthëŠ” depthì—ë„ augmentation ì ìš©:
- Noise ì¶”ê°€ â†’ ì„¼ì„œ ì˜¤ì°¨ ì‹œë®¬ë ˆì´ì…˜
- Blur ì ìš© â†’ Edge bleeding ì‹œë®¬ë ˆì´ì…˜  
- Hole ìƒì„± â†’ ì„¼ì„œ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜

ResNet-SANì€ RGB augmentationë§Œ ì¡´ì¬
```

**ì°¸ê³ **: RGB-onlyì´ë¯€ë¡œ sparse depth augmentationì€ í•´ë‹¹ ì—†ìŒ.
í•˜ì§€ë§Œ GT depthì— noiseë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì€ robustness í–¥ìƒì— ë„ì›€ë  ìˆ˜ ìˆìŒ.

#### âŒ 3. Advanced Augmentation ë¯¸í™œìš©
```python
# augmentations_kitti_compatible.pyì— êµ¬í˜„ë˜ì–´ ìˆìœ¼ë‚˜ ë¯¸ì‚¬ìš©
class KITTIAdvancedTrainTransform:
    """RandAugment, RandomErasing, MixUp, CutMix"""
    # êµ¬í˜„ë¨ but ì‹¤ì œ í•™ìŠµì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
```

#### âŒ 4. Normalization ë°©ì‹
| í•­ëª© | ResNet-SAN | G2-MonoDepth |
|------|------------|--------------|
| RGB Normalize | ImageNet mean/std | ì—†ìŒ (0-1 ë²”ìœ„) |
| Depth Normalize | ì—†ìŒ | Robust Standardization (MAD) |

---

## 2. Loss í•¨ìˆ˜ ë¹„êµ

### 2.1 í˜„ì¬ ResNet-SAN Loss êµ¬ì¡°

```python
# SSISilogLoss (ssi_silog_loss.py)
total_loss = ssi_weight * SSI_Loss + silog_weight * Silog_Loss
```

#### SSI Loss (Scale-Shift Invariant)
```python
def compute_ssi_loss(self, pred_depth, gt_depth, mask):
    diff = (pred_depth[mask] - gt_depth[mask])
    diff2 = diff ** 2
    mean = diff.mean()
    var = diff2.mean() - mean ** 2
    ssi_loss = var + self.alpha * mean ** 2  # alpha=0.85
    return ssi_loss
```

ìˆ˜ì‹:
$$\mathcal{L}_{SSI} = \text{Var}(d - \hat{d}) + \alpha \cdot \text{Mean}(d - \hat{d})^2$$

#### Silog Loss
```python
def compute_silog_loss(self, pred_depth, gt_depth, mask):
    log_diff = torch.log(pred_depth) - torch.log(gt_depth)
    silog1 = torch.mean(log_diff ** 2)
    silog2 = self.silog_ratio2 * (log_diff.mean() ** 2)  # ratio2=0.85
    silog_loss = torch.sqrt(silog1 - silog2 + 1e-8)
    return silog_loss
```

ìˆ˜ì‹:
$$\mathcal{L}_{Silog} = \sqrt{E[(\log d - \log \hat{d})^2] - \lambda \cdot E[\log d - \log \hat{d}]^2}$$

### 2.2 G2-MonoDepth Loss êµ¬ì¡°

```python
# 3-Term Loss
total_loss = loss_adepth + loss_rdepth + 0.5 * loss_rgrad
```

#### Absolute Depth Loss (L1)
```python
loss_adepth = L1(pred_depth, gt_depth, mask)
```

ìˆ˜ì‹:
$$\mathcal{L}_{adepth} = \frac{1}{N}\sum_{i \in M} |d_i - \hat{d}_i|$$

#### Relative Depth Loss (Standardized L1)
```python
# Robust Standardization
sta_depth = (pred - mean_pred) / mad_pred
sta_gt = (gt - mean_gt) / mad_gt
loss_rdepth = L1(sta_depth, sta_gt, mask)
```

ìˆ˜ì‹:
$$z_d = \frac{d - \mu_d}{\sigma_{MAD}}, \quad z_{\hat{d}} = \frac{\hat{d} - \mu_{\hat{d}}}{\sigma_{MAD}}$$
$$\mathcal{L}_{rdepth} = \frac{1}{N}\sum_{i \in M} |z_{d,i} - z_{\hat{d},i}|$$

#### Gradient Loss (Multi-Scale Sobel)
```python
def forward(self, depth, gt, mask):
    total_loss = 0
    for scale in [1, 2, 4, 8]:
        grad_pred = sobel_gradient(downsample(depth, scale))
        grad_gt = sobel_gradient(downsample(gt, scale))
        total_loss += L1(grad_pred, grad_gt, mask)
    return total_loss / 4
```

ìˆ˜ì‹:
$$\mathcal{L}_{rgrad} = \frac{1}{4}\sum_{s \in \{1,2,4,8\}} \left( |G_x^s(d) - G_x^s(\hat{d})| + |G_y^s(d) - G_y^s(\hat{d})| \right)$$

### 2.3 Loss ë¹„êµí‘œ

| í•­ëª© | ResNet-SAN (SSI-Silog) | G2-MonoDepth |
|------|------------------------|--------------|
| **êµ¬ì„±** |
| Absolute Loss | Silog (log domain) | L1 (linear domain) |
| Relative Loss | SSI (variance based) | Standardized L1 |
| Gradient Loss | âŒ ì—†ìŒ | âœ… Multi-scale Sobel |
| **íŠ¹ì„±** |
| Scale Invariance | SSIë¡œ ë‹¬ì„± | Standardizationìœ¼ë¡œ ë‹¬ì„± |
| Edge ë³´ì¡´ | âŒ ëª…ì‹œì  ì—†ìŒ | âœ… Gradient Loss |
| Outlier Robustness | Silog (log space) | MAD Standardization |
| **Weight** |
| Default | SSI:0.5 + Silog:0.5 | A:1.0 + R:1.0 + G:0.5 |

### 2.4 í•µì‹¬ ì°¨ì´ì  ë¶„ì„

#### 1ï¸âƒ£ Gradient Lossì˜ ìœ ë¬´

**ResNet-SAN**: Gradient Loss ì—†ìŒ
```
ë¬¸ì œì :
- Edge ì˜ì—­ì—ì„œ depthê°€ blurë  ìˆ˜ ìˆìŒ
- ì „ì²´ ë§µì˜ êµ¬ì¡°ì  ì¼ê´€ì„± ë¶€ì¡± ê°€ëŠ¥
- ê°ì²´ ê²½ê³„ê°€ ë¶ˆë¶„ëª…í•´ì§ˆ ìˆ˜ ìˆìŒ
```

**G2-MonoDepth**: Multi-Scale Gradient Loss
```
ì¥ì :
- Edge ì„ ëª…ë„ ìœ ì§€
- ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ êµ¬ì¡° ë³´ì¡´
- ì „ì²´ depth map ì¼ê´€ì„± í–¥ìƒ
```

#### 2ï¸âƒ£ Relative Loss ê³„ì‚° ë°©ì‹

**ResNet-SAN (SSI)**:
```python
# Variance + scaled meanÂ²
diff = pred - gt
var = E[diffÂ²] - E[diff]Â²
loss = var + alpha * meanÂ²
```
- Variance ê¸°ë°˜ (2ì°¨ í†µê³„ëŸ‰)
- alphaë¡œ bias í˜ë„í‹° ì¡°ì ˆ
- ë‹¨ì¼ ì—°ì‚°ìœ¼ë¡œ ê³„ì‚°

**G2-MonoDepth (Standardized L1)**:
```python
# MAD ê¸°ë°˜ ì •ê·œí™” í›„ L1
z_pred = (pred - mean) / mad
z_gt = (gt - mean) / mad  
loss = L1(z_pred, z_gt)
```
- MAD (Mean Absolute Deviation) ì‚¬ìš©
- Outlierì— ë” ê°•ê±´
- ëª…ì‹œì  standardization

#### 3ï¸âƒ£ Absolute Loss ê³„ì‚° ë°©ì‹

**ResNet-SAN (Silog)**:
```python
# Log spaceì—ì„œ ê³„ì‚°
log_diff = log(pred) - log(gt)
loss = sqrt(E[log_diffÂ²] - Î»Â·E[log_diff]Â²)
```
- Log space â†’ ìƒëŒ€ì  ì˜¤ì°¨ì— ì§‘ì¤‘
- ë©€ë¦¬ ìˆëŠ” ê°ì²´ ì˜¤ì°¨ ì™„í™”
- Scale-invariant íŠ¹ì„±

**G2-MonoDepth (L1)**:
```python
# Linear spaceì—ì„œ ê³„ì‚°
loss = mean(|pred - gt|)
```
- Linear space â†’ ì ˆëŒ€ ì˜¤ì°¨
- ë‹¨ìˆœí•˜ê³  ì§ê´€ì 
- ê·¼ê±°ë¦¬ ì •í™•ë„ ì¤‘ì‹œ

---

## 3. ìƒì„¸ ë¶„ì„

### 3.1 SSI Loss vs Relative (Standardized) Loss

| ì¸¡ë©´ | SSI | Standardized L1 |
|------|-----|-----------------|
| **ìˆ˜í•™ì  ê¸°ë°˜** | Variance ìµœì†Œí™” | Distribution ì •í•© |
| **Scale ë³´ì •** | Implicit (variance) | Explicit (Ã·std) |
| **Shift ë³´ì •** | alpha íŒŒë¼ë¯¸í„° | mean ì œê±° |
| **Outlier ì²˜ë¦¬** | ì œê³±ìœ¼ë¡œ ë¯¼ê° | MADë¡œ ê°•ê±´ |
| **ê³„ì‚° ë³µì¡ë„** | ë‚®ìŒ | ì¤‘ê°„ (2íšŒ í†µê³„ ê³„ì‚°) |

#### SSI Loss íŠ¹ì„±:
```
ì¥ì :
- ë‹¨ì¼ ìˆ˜ì‹ìœ¼ë¡œ scale-shift invariance
- ê³„ì‚° íš¨ìœ¨ì 
- ì˜ ì—°êµ¬ëœ ë°©ë²•

ë‹¨ì :
- ì œê³± ì—°ì‚°ìœ¼ë¡œ outlierì— ë¯¼ê°
- alpha íŠœë‹ í•„ìš”
```

#### Standardized L1 íŠ¹ì„±:
```
ì¥ì :
- MADë¡œ outlierì— ê°•ê±´
- ì§ê´€ì ì¸ í•´ì„ (z-score ë¹„êµ)
- ë¶„í¬ ì •í•© ê´€ì 

ë‹¨ì :
- ì¶”ê°€ í†µê³„ ê³„ì‚° í•„ìš”
- predì™€ gt ê°ê° ì •ê·œí™” í•„ìš”
```

### 3.2 Silog Loss vs L1 Loss

| ì¸¡ë©´ | Silog | L1 |
|------|-------|-----|
| **Domain** | Log | Linear |
| **ì›ê±°ë¦¬ ê°ì²´** | ì˜¤ì°¨ ì™„í™” | ì˜¤ì°¨ ê·¸ëŒ€ë¡œ |
| **ê·¼ê±°ë¦¬ ê°ì²´** | ì˜¤ì°¨ ì¦í­ | ì˜¤ì°¨ ê·¸ëŒ€ë¡œ |
| **ìˆ˜ì¹˜ ì•ˆì •ì„±** | log(0) ìœ„í—˜ | ì•ˆì „ |

#### Silog íŠ¹ì„±:
```
log(pred) - log(gt) = log(pred/gt)

pred=10, gt=9  â†’ log(10/9) â‰ˆ 0.105  (11% ìƒëŒ€ ì˜¤ì°¨)
pred=100, gt=90 â†’ log(100/90) â‰ˆ 0.105  (ë™ì¼!)

â†’ ìƒëŒ€ì  ì˜¤ì°¨ì— ì§‘ì¤‘, ê±°ë¦¬ì— ê´€ê³„ì—†ì´ ê³µí‰í•œ í•™ìŠµ
```

#### L1 íŠ¹ì„±:
```
|pred - gt|

pred=10, gt=9   â†’ |10-9| = 1
pred=100, gt=90 â†’ |100-90| = 10

â†’ ì ˆëŒ€ ì˜¤ì°¨ ê¸°ì¤€, ê·¼ê±°ë¦¬ ì •í™•ë„ì— ìœ ë¦¬
```

### 3.3 Gradient Loss ë¶€ì¬ì˜ ì˜í–¥

```
í˜„ì¬ ResNet-SAN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SSI Loss          â”‚  â†’ ì „ì²´ ë¶„í¬ ì •í•©
â”‚  +                 â”‚
â”‚  Silog Loss        â”‚  â†’ ìŠ¤ì¼€ì¼ ì •í™•ë„
â”‚                    â”‚
â”‚  = Total Loss      â”‚  â†’ Edge ì •ë³´ ì—†ìŒ!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ê²°ê³¼:
- ê°ì²´ ê²½ê³„ì—ì„œ depth ë¶ˆì—°ì†ì„± blur
- ì „ì²´ ë§µì˜ êµ¬ì¡°ì  ì¼ê´€ì„± ë¶€ì¡±
- "ì „ì²´ ë§µì´ ì•ˆ ì¢‹ë‹¤"ëŠ” ë¬¸ì œì™€ ì—°ê´€ ê°€ëŠ¥
```

```
G2-MonoDepth:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Absolute Loss     â”‚  â†’ ì ˆëŒ€ ì •í™•ë„
â”‚  +                 â”‚
â”‚  Relative Loss     â”‚  â†’ ìƒëŒ€ ë¶„í¬
â”‚  +                 â”‚
â”‚  Gradient Loss     â”‚  â†’ Edge ë³´ì¡´!
â”‚                    â”‚
â”‚  = Total Loss      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ê²°ê³¼:
- ê°ì²´ ê²½ê³„ ì„ ëª…ë„ ìœ ì§€
- Multi-scale êµ¬ì¡° ë³´ì¡´
- ì „ì²´ ë§µ ì¼ê´€ì„± í–¥ìƒ
```

---

## 4. ê°œì„  ì œì•ˆ

### 4.1 ë°ì´í„° ì²˜ë¦¬ ê°œì„ 

#### Priority 1: Horizontal Flip ì¶”ê°€
```python
# transforms.py ìˆ˜ì •
def train_transforms(sample, image_shape, jittering, crop_train_borders):
    ...
    # ì¶”ê°€: Horizontal flip (50%)
    if random.random() < 0.5:
        sample = horizontal_flip_sample(sample)
    ...
```

#### Priority 2: Advanced Augmentation í™œì„±í™”
```yaml
# YAML config
augmentation:
  use_advanced: true
  rand_augment_n: 2
  rand_augment_m: 9
```

### 4.2 Loss ê°œì„ 

#### Priority 1: Gradient Loss ì¶”ê°€ (ê°•ë ¥ ê¶Œì¥)
```python
# ìƒˆ íŒŒì¼: gradient_loss.py
class MultiScaleGradientLoss(nn.Module):
    def __init__(self, scales=[1, 2, 4, 8]):
        ...
    
    def forward(self, pred, gt, mask):
        total = 0
        for s in self.scales:
            grad_p = self.sobel(F.avg_pool2d(pred, s))
            grad_g = self.sobel(F.avg_pool2d(gt, s))
            total += F.l1_loss(grad_p * mask, grad_g * mask)
        return total / len(self.scales)
```

```yaml
# YAML config
loss:
  supervised_method: ssi-silog
  ssi_weight: 0.4
  silog_weight: 0.4
  gradient_weight: 0.2  # ìƒˆë¡œ ì¶”ê°€
```

#### Priority 2: Robust Standardization ê²€í† 
í˜„ì¬ SSI Lossë„ íš¨ê³¼ì ì´ë‚˜, outlierê°€ ë§ì€ í™˜ê²½ì—ì„œëŠ” MAD ê¸°ë°˜ standardization ê²€í† 

---

## 5. ìš”ì•½

### 5.1 ë°ì´í„° ì²˜ë¦¬ Gap

| í•­ëª© | í˜„ì¬ ìƒíƒœ | ì œì•ˆ |
|------|----------|------|
| Horizontal Flip | âŒ ì—†ìŒ | âœ… ì¶”ê°€ (ì‰¬ì›€) |
| Advanced Aug | êµ¬í˜„ë¨/ë¯¸ì‚¬ìš© | âœ… í™œì„±í™” ê²€í†  |
| Depth Aug | N/A (RGB-only) | - |

### 5.2 Loss Gap

| í•­ëª© | í˜„ì¬ ìƒíƒœ | ì œì•ˆ |
|------|----------|------|
| Gradient Loss | âŒ ì—†ìŒ | âœ… ì¶”ê°€ (ê¶Œì¥) |
| Robust Normalization | SSI ì‚¬ìš© | í˜„ì¬ë¡œ ì¶©ë¶„ |
| Absolute Loss | Silog | í˜„ì¬ë¡œ ì¶©ë¶„ |

### 5.3 ìµœì¢… ê¶Œì¥ì‚¬í•­

```
ğŸ”´ ì¦‰ì‹œ ì ìš©:
   1. Gradient Loss ì¶”ê°€ â†’ ì „ì²´ ë§µ ì¼ê´€ì„± ê°œì„ 

ğŸŸ¡ ê²€í†  í›„ ì ìš©:
   2. Horizontal Flip ì¶”ê°€ â†’ ë°ì´í„° ë‹¤ì–‘ì„±
   3. Advanced Augmentation í™œì„±í™” â†’ Robustness

ğŸŸ¢ í˜„ì¬ ìœ ì§€:
   - SSI Loss (íš¨ê³¼ì ì¸ scale-invariance)
   - Silog Loss (log-domain accuracy)
```

---

## 6. ì°¸ê³ : ì½”ë“œ ìœ„ì¹˜

| íŒŒì¼ | ì—­í•  |
|------|------|
| `packnet_sfm/datasets/transforms.py` | Transform ì •ì˜ |
| `packnet_sfm/datasets/augmentations.py` | Augmentation í•¨ìˆ˜ |
| `packnet_sfm/datasets/augmentations_kitti_compatible.py` | Advanced Aug (ë¯¸ì‚¬ìš©) |
| `packnet_sfm/losses/supervised_loss.py` | Loss í•¨ìˆ˜ íŒ©í† ë¦¬ |
| `packnet_sfm/losses/ssi_silog_loss.py` | SSI-Silog Loss êµ¬í˜„ |
