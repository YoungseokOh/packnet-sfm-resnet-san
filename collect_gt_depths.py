#!/usr/bin/env python3
"""
NPU íŒŒì¼ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ GT depth íŒŒì¼ ì°¾ì•„ì„œ ë³µì‚¬
"""

import json
import os
import shutil
from pathlib import Path


def find_and_copy_gt_depths():
    """NPU íŒŒì¼ì— í•´ë‹¹í•˜ëŠ” GT depth ì°¾ì•„ì„œ ë³µì‚¬"""
    
    print("=" * 90)
    print("ğŸ” NPU íŒŒì¼ì— ëŒ€í•œ GT Depth ì°¾ê¸° ë° ë³µì‚¬")
    print("=" * 90)
    print()
    
    # ê²½ë¡œ ì„¤ì •
    npu_folder = '/workspace/packnet-sfm/outputs/sigmoid_prediction_from_aiwbin_npu'
    splits_dir = '/workspace/data/ncdb-cls-640x384/splits'
    output_folder = '/workspace/packnet-sfm/outputs/sigmoid_prediction_GT'
    
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(output_folder, exist_ok=True)
    print(f"ğŸ“ Output folder created: {output_folder}\n")
    
    # NPU íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    npu_files = sorted([f.name.replace('.npy', '') for f in Path(npu_folder).glob('*.npy')])
    print(f"ğŸ“‹ NPU files ({len(npu_files)}):")
    for i, fname in enumerate(npu_files, 1):
        print(f"   {i:2d}. {fname}")
    print()
    
    # ëª¨ë“  split JSON ë¡œë“œ (train, val, test)
    print(f"ğŸ“– Loading all split JSONs from: {splits_dir}")
    all_data = {}
    for split_name in ['combined_train.json', 'combined_val.json', 'combined_test.json']:
        split_path = os.path.join(splits_dir, split_name)
        if os.path.exists(split_path):
            with open(split_path, 'r') as f:
                split_data = json.load(f)
            print(f"   â€¢ {split_name}: {len(split_data)} entries")
            # new_filenameì„ í‚¤ë¡œ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
            for item in split_data:
                all_data[item['new_filename']] = item
    print(f"   âœ… Total loaded: {len(all_data)} entries\n")
    
    # new_filenameì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ (all_dataë¡œ ë³€ê²½)
    test_dict = all_data
    
    print("ğŸ”„ Finding and copying GT depth files...")
    print("-" * 90)
    
    found = 0
    not_found = 0
    copied = 0
    
    for npu_filename in npu_files:
        if npu_filename in test_dict:
            item = test_dict[npu_filename]
            
            # image_pathì—ì„œ ë””ë ‰í† ë¦¬ êµ¬ì¡° íŒŒì•…
            # /workspace/data/ncdb-cls-640x384/2025-07-11_15-39-30_243127_B/synced_data/image_a6/0000000567.png
            image_path = item['image_path']
            
            # image_a6ë¥¼ newest_depth_mapsë¡œ ë³€ê²½í•˜ê³  .pngë¥¼ ìœ ì§€
            gt_path = image_path.replace('/image_a6/', '/newest_depth_maps/')
            
            print(f"âœ“ {npu_filename}")
            print(f"  Image: {image_path}")
            print(f"  GT   : {gt_path}")
            
            if os.path.exists(gt_path):
                # GT íŒŒì¼ ë³µì‚¬
                output_path = os.path.join(output_folder, f"{npu_filename}.png")
                shutil.copy2(gt_path, output_path)
                print(f"  âœ… Copied to: {output_path}")
                copied += 1
            else:
                print(f"  âŒ GT file not found!")
                not_found += 1
            
            print()
            found += 1
        else:
            print(f"âš ï¸  {npu_filename}: Not found in test JSON")
            not_found += 1
            print()
    
    print("-" * 90)
    print(f"\nğŸ“Š Summary:")
    print(f"   â€¢ Total NPU files: {len(npu_files)}")
    print(f"   â€¢ Found in JSON: {found}")
    print(f"   â€¢ GT files copied: {copied}")
    print(f"   â€¢ Not found: {not_found}")
    print()
    
    # ë³µì‚¬ëœ íŒŒì¼ í™•ì¸
    copied_files = sorted(list(Path(output_folder).glob('*.png')))
    if copied_files:
        print(f"ğŸ“ Copied GT files ({len(copied_files)}):")
        for i, f in enumerate(copied_files, 1):
            file_size = os.path.getsize(f) / 1024  # KB
            print(f"   {i:2d}. {f.name} ({file_size:.1f} KB)")
        print()
    
    print("=" * 90)
    print("âœ… GT depth collection complete!")
    print(f"ğŸ“ GT files saved to: {output_folder}")
    print("=" * 90)


if __name__ == '__main__':
    find_and_copy_gt_depths()
